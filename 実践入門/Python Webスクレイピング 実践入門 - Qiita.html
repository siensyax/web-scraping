<!DOCTYPE html><html><head><meta charset="utf-8" /><title>Python Webスクレイピング 実践入門 - Qiita</title><meta content="width=device-width,initial-scale=1,shrink-to-fit=no" name="viewport" /><meta content="#55c500" name="theme-color" /><meta content="XWpkTG32-_C4joZoJ_UsmDUi-zaH-hcrjF6ZC_FoFbk" name="google-site-verification" /><link href="/manifest.json" rel="manifest" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="aNCjy5X/r5m1UYdYL0sWhb//PNRph+VV5a8A+zkeTNJJeZwTkWzRpC1EN8jCnF1qb7xlrWFJB3iHdVtEGOBw+Q==" /><link rel="shortcut icon" type="image/x-icon" href="https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico" /><link rel="apple-touch-icon" type="image/png" href="https://cdn.qiita.com/assets/favicons/public/apple-touch-icon-ec5ba42a24ae923f16825592efdc356f.png" /><link rel="stylesheet" media="all" href="https://cdn.qiita.com/assets/public/style-374b965692f66f218d89cd715864579b.min.css" /><script src="https://cdn.qiita.com/assets/public/v3-bundle-5c87a3f3d074de5070ca70d8e61bbdd7.min.js" defer="defer"></script><meta name="twitter:card" content="summary_large_image"><meta content="@Qiita" name="twitter:site" /><meta content="@Azunyan1111_" name="twitter:creator" /><meta property="og:type" content="article"><meta property="og:title" content="Python Webスクレイピング 実践入門 - Qiita"><meta property="og:image" content="https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Fogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-1.2.2&amp;w=1200&amp;mark=https%3A%2F%2Fqiita-user-contents.imgix.net%2F~text%3Fixlib%3Drb-1.2.2%26w%3D840%26h%3D380%26txt%3DPython%2520Web%25E3%2582%25B9%25E3%2582%25AF%25E3%2583%25AC%25E3%2582%25A4%25E3%2583%2594%25E3%2583%25B3%25E3%2582%25B0%2520%25E5%25AE%259F%25E8%25B7%25B5%25E5%2585%25A5%25E9%2596%2580%26txt-color%3D%2523333%26txt-font%3DAvenir-Black%26txt-size%3D54%26txt-clip%3Dellipsis%26txt-align%3Dcenter%252Cmiddle%26s%3D9ffb222c21868d841e49f72b54f27d29&amp;mark-align=center%2Cmiddle&amp;blend=https%3A%2F%2Fqiita-user-contents.imgix.net%2F~text%3Fixlib%3Drb-1.2.2%26w%3D840%26h%3D500%26txt%3D%2540Azunyan1111%26txt-color%3D%2523333%26txt-font%3DAvenir-Black%26txt-size%3D45%26txt-align%3Dright%252Cbottom%26s%3Df61bfffc139306297f0988ea6ed375d8&amp;blend-align=center%2Cmiddle&amp;blend-mode=normal&amp;s=013c0064f7f3daf54b28d4a098cc5373"><meta property="og:description" content="PythonによるWebスクレイピングの実践入門を書きたいと思います。

概論的なところは除いて、フィーリングで理解していくスタイルで行きたいと思います。

※追記
本記事は少し難しいやり方をとっていますが、学習すると言う意味ではとて..."><meta content="https://qiita.com/Azunyan1111/items/9b3d16428d2bcc7c9406" property="og:url" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><meta content="Python,スクレイピング" name="keywords" /><script>window.frtn=window.frtn||function(){ (frtn.q=frtn.q||[]).push(arguments) };
frtn("init",{
service_id:"cova_248",
site_id:"site_134",
tag_id:"tag_283"
});
frtn("send","pageview");</script><script defer="" src="https://frtn.socdm.com/tags/insight.js" type="text/javascript"></script><script>!function(t,e){if(void 0===e[t]){e[t]=function(){e[t].clients.push(this),this._init=[Array.prototype.slice.call(arguments)]},e[t].clients=[];for(var r=function(t){return function(){return this["_"+t]=this["_"+t]||[],this["_"+t].push(Array.prototype.slice.call(arguments)),this}},s=["blockEvents","unblockEvents","setSignedMode","setAnonymousMode","resetUUID","addRecord","fetchGlobalID","set","trackEvent","trackPageview","trackClicks","ready"],n=0;n<s.length;n++){var c=s[n];e[t].prototype[c]=r(c)}var o=document.createElement("script");o.type="text/javascript",o.async=!0,o.src=("https:"===document.location.protocol?"https:":"http:")+"//cdn.treasuredata.com/sdk/2.1/td.min.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(o,a)}}("Treasure",this);

// Configure an instance for your database
var td = new Treasure({
  host: 'in.treasuredata.com',
  writeKey: '10614/f5a4453704ad12facc47fe5281fd57526a6119e9',
  database: 'qiita_public',
  startInSignedMode: true
});

// Enable cross-domain tracking
td.set('$global', 'td_global_id', 'td_global_id');
// Track pageview information to 'pageviews' table
td.set('pageviews_all', {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"Azunyan1111","type":"items","id":"9b3d16428d2bcc7c9406"}})
td.trackPageview('pageviews_all');</script><script>td.set('pageviews_anonymous_user', {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"Azunyan1111","type":"items","id":"9b3d16428d2bcc7c9406"}})
td.trackPageview('pageviews_anonymous_user');</script></head><body><div class="allWrapper"><div class="st-HeaderContainer"><div id="GlobalHeader-react-component-b17aa712-e906-4deb-bd6e-96cd8bc1c727"><div class="st-Header"><div class="st-Header_container"><div class="st-Header_start"><a href="/" class="st-Header_logo mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 426.57 130"><circle cx="167.08" cy="21.4" r="12.28"></circle><path d="M250.81 29.66h23.48v18.9h-23.48z"></path><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z"></path><circle cx="216.33" cy="21.4" r="12.28"></circle></svg></a><div><div class="st-Header_realmSelector" tabindex="0"><span class="fa fa-fw fa-caret-down"></span></div><div class="st-Header_dropdown st-RealmSelector"><div class="st-RealmSelector_realms"><a class="st-Header_dropdownItem st-RealmItem" href="https://qiita.com/"><div class="st-RealmItem_statusIcon"><span class="fa fa-fw fa-check"></span></div><div class="st-RealmItem_humanName">Qiita</div></a></div><hr/><div class="st-RealmSelector_supplements"><div class="st-RealmSelector_label">ログイン中のチームがありません</div><a href="https://teams-center.qiita.com/find_team" class="st-Header_dropdownItem st-RealmSelectorSupplement"><div class="st-RealmSelectorSupplement_icon"><span class="fa fa-fw fa-sign-in"></span></div><div>Qiita Team にログイン...</div></a></div></div></div><div><div class="st-Header_community" tabindex="0">コミュニティ<span class="fa fa-fw fa-caret-down ml-1of2"></span></div><div class="st-Header_dropdown"><a href="/users" class="st-Header_dropdownItem"><span class="fa fa-fw fa-users mr-1of2"></span>ユーザー一覧</a><a href="/organizations" class="st-Header_dropdownItem"><span class="fa fa-fw fa-building-o mr-1of2"></span>Organization一覧</a><a href="/advent-calendar" class="st-Header_dropdownItem"><span class="fa fa-fw fa-calendar mr-1of2"></span>アドベントカレンダー</a><div class="st-Header_dropdownSeparator"></div><a href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-search mr-1of2"></span>Qiita Jobs</a><a href="https://qiitadon.com/" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-comments-o mr-1of2"></span>Qiitadon (β)</a><a href="https://zine.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-newspaper-o mr-1of2"></span>Qiita:Zine</a><div class="st-Header_dropdownSeparator"></div><a href="https://help.qiita.com/ja/articles/qiita-community-guideline" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-book mr-1of2"></span>コミュニティガイドライン</a><a href="https://help.qiita.com/ja/articles/qiita-article-guideline" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-book mr-1of2"></span>良い記事を書くために</a></div></div><form class="st-Header_search" action="/search" method="get"><span class="fa fa-search"></span><input type="search" class="st-Header_searchInput" autoComplete="off" placeholder="キーワードを入力" value="" name="q" required=""/></form><div class="st-Header_searchButton"><span class="fa fa-search"></span></div></div><div class="st-Header_end"><a class="st-Header_signupButton" href="/signup?redirect_to=%2FAzunyan1111%2Fitems%2F9b3d16428d2bcc7c9406">ユーザ登録</a><a class="st-Header_loginLink" href="/login?redirect_to=%2FAzunyan1111%2Fitems%2F9b3d16428d2bcc7c9406">ログイン</a></div><div class="st-Header_overlay"></div><form class="st-Header_searchModal" action="/search" method="get"><input type="text" class="st-Header_searchModalInput" autoComplete="off" placeholder="キーワードを入力" value="" name="q" required=""/></form></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="GlobalHeader" data-dom-id="GlobalHeader-react-component-b17aa712-e906-4deb-bd6e-96cd8bc1c727">{"unreadNotificationsCount":null,"realms":[{"humanName":"Qiita","isCurrentRealm":true,"isQiita":true,"isQiitaTeam":false,"loggedInUser":null,"teamId":null,"url":"https://qiita.com/"}],"teamFindUrl":"https://teams-center.qiita.com/find_team","isTeamOnlyUser":null,"currentUser":null}</script>
      
</div><div class="st-HeaderAlert st-HeaderAlert-warning"><div class="st-HeaderAlert_body"></div></div><div class="ac-CampaignLink"><div class="ac-CampaignLink_container"><a href="/advent-calendar/2019">Qiita Advent Calendar 2019 開催中！ 最高に盛り上がる年末にしていきましょう :)</a><a href="/advent-calendar/2019">&gt; カレンダーを見る</a></div></div><script type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"/","name":"Qiita"}},{"@type":"ListItem","position":2,"item":{"@id":"/tags/%23%3CQiita::Graph::Result:0x00005576ee466238%3E","name":"Python"}}]}</script><script>td.trackEvent('pageviews_article',{
    user_id: "",
    article_id: "443131",
    article_uuid: "9b3d16428d2bcc7c9406",
    td_description: "&quot;PythonによるWebスクレイピングの実践入門を書きたいと思います。\n\n概論的なところは除いて、フィーリングで理解していくスタイルで行きたいと思います。\n\n※追記\n本記事は少し難しいやり方をとっていますが、学習すると言う意味ではとても価値あるものだと思います。\n本記事を読み終えた後はこちらのテクニック編わご覧になるとサクッと出来たりします。\n[Python Webスクレイピング テクニック集「取得できない値は無い」JavaScript対応](https://qiita.com/Azunyan1111/items/b161b998790b1db2ff7a)\n\n## やること\n最終的には「1時間ごとに日本経済新聞にアクセスを行いその時の日経平均株価をcsvに記録する」\n\nプログラムを組んでみたいと思います。\n### 注意\n注意事項です。よく読みましょう。\n[岡崎市立中央図書館事件(Librahack事件) - Wikipedia](https://ja.wikipedia.org/wiki/%E5%B2%A1%E5%B4%8E%E5%B8%82%E7%AB%8B%E4%B8%AD%E5%A4%AE%E5%9B%B3%E6%9B%B8%E9%A4%A8%E4%BA%8B%E4%BB%B6)\n[Webスクレイピングの注意事項一覧](https://qiita.com/nezuq/items/c5e827e1827e7cb29011)\n\n## 何を使うの？\n言語:Python 2.7.12\nライブラリ:urllib2、BeautifulSoup、csv、datetime、time\n\nurllib2はURLにアクセスするために必要です。\nBeautifulSoupはアクセスして取得したファイルを開くxmlパーサー的なものです\ncsvファイルを操作する時に必要なライブラリです。\ndatetimeは時間を取得するためのライブラリです\n\n## ライブラリインストール\nurllib2はPythonをインストールするとインストールされてまいす。\nBeautifulSoupをインストールするにはpipコマンドを使います\n\n```shell.sh\n$ pip install beautifulsoup4\n```\n\n### 手始めに日本経済新聞のページタイトルを取得してみよう！\n\nまず手始めに日本経済新聞にPythonにてアクセスを行い、そのHTMLを取得します。\n\nそのあとにBeautifulSoupで扱える形にし、\n\nその扱える形からページタイトルを取得し、出力します。\n\nまた、今回はページのタイトルだけを取得するとイメージがわきにくいかもしれないので、title要素を入手し、タイトル要素の中からタイトルを取得したいと思います。\n\n```getNikkeiWebPageTitle.py\n# coding: UTF-8\nimport urllib2\nfrom bs4 import BeautifulSoup\n\n# アクセスするURL\nurl = \u0026amp;quot;http://www.nikkei.com/\u0026amp;quot;\n\n# URLにアクセスする htmlが帰ってくる → \u0026amp;lt;html\u0026amp;gt;\u0026amp;lt;head\u0026amp;gt;\u0026amp;lt;title\u0026amp;gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026amp;lt;/title\u0026amp;gt;\u0026amp;lt;/head\u0026amp;gt;\u0026amp;lt;body....\nhtml = urllib2.urlopen(url)\n\n# htmlをBeautifulSoupで扱う\nsoup = BeautifulSoup(html, \u0026amp;quot;html.parser\u0026amp;quot;)\n\n# タイトル要素を取得する → \u0026amp;lt;title\u0026amp;gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026amp;lt;/title\u0026amp;gt;\ntitle_tag = soup.title\n\n# 要素の文字列を取得する → 経済、株価、ビジネス、政治のニュース:日経電子版\ntitle = title_tag.string\n\n# タイトル要素を出力\nprint title_tag\n\n# タイトルを文字列を出力\nprint title\n\n```\n\nこれを実行すると下記の結果が返ってきます。\n\n```shell.sh\n$ python getNikkeiWebPageTitle.py\n\u0026amp;lt;title\u0026amp;gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026amp;lt;/title\u0026amp;gt;\n経済、株価、ビジネス、政治のニュース:日経電子版\n```\n\nちなみに\n\n```print.py\nprint soup.title.string\n```\n\nこの場合でも同様の結果を得られます。\n\nこれで大体のイメージをつかめたと思います。\n\n## 実践！\n今回の目標は「1時間ごとに日本経済新聞にアクセスを行いその時の日経平均株価をcsvに記録する」と言うことです。\nフログラム手順を確認すると\n\n1.日本経済新聞の日経平均株価ページにアクセスし、HTMLを取得する\n3.BeautifulSoupを使い日経平均株価を取得する\n4.csvに日付と時間と日経平均株価の値を1レコードで記述する\n\ncsvに関してはHeaderは使用しません。\n\nではではやってみましょう。\n\n### 日経平均株価ページへアクセス\n\nまず始めに日経平均株価のページへアクセスします。\n\nURLはあらかじめブラウザから自分で調べるのがセオリーですね\n\n調べると「日本経済新聞→マーケット→株」のページにありますね\n\n先ほどのプラグラムを流用します\n\n```getNikkeiHeikin.py\n# coding: UTF-8\nimport urllib2\nfrom bs4 import BeautifulSoup\n\n# アクセスするURL\nurl = \u0026amp;quot;http://www.nikkei.com/markets/kabu/\u0026amp;quot;\n\n# URLにアクセスする htmlが帰ってくる → \u0026amp;lt;html\u0026amp;gt;\u0026amp;lt;head\u0026amp;gt;\u0026amp;lt;title\u0026amp;gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026amp;lt;/title\u0026amp;gt;\u0026amp;lt;/head\u0026amp;gt;\u0026amp;lt;body....\nhtml = urllib2.urlopen(url)\n\n# htmlをBeautifulSoupで扱う\nsoup = BeautifulSoup(html, \u0026amp;quot;html.parser\u0026amp;quot;)\n\n# タイトルを文字列を出力\nprint soup.title.string\n```\n\nこれによりタイトルが出力されます。\n\n```shell.sh\n$ python getNikkiHeikin.py\n\u0026amp;gt;\u0026amp;gt;株式　：マーケット　：日経電子版\n```\n### 日経平均株価取得\n次に日経平均株価を取得します。\n\nブラウザで[日本経済新聞\u0026amp;gt;マーケット\u0026amp;gt;株](http://www.nikkei.com/markets/kabu/)を開いてみましょう\n\nこのページの一番上から少し下のほうに日経平均株価が載っています。\n\nこれを取得するには、このデータのHTML上での位置を探る必要があります。\n\n日経平均株価を右クリックして、「検証」を押しましょう。\n\nするとこのような画面になると思います\n\n![スクリーンショット 2016-12-01 17.59.17.png](https://qiita-image-store.s3.amazonaws.com/0/110135/62c26aaf-fe38-6e19-4a45-edca703726d7.png)\n\nspan要素でClass=\u0026amp;quot;mkc-stock_prices\u0026amp;quot;となっています。\n\nこれで位置がわかりました。\n\nでは実際にBeautifulSoupでprintしてみましょう。\n\n```getNikeiHeikin.py\n# coding: UTF-8\nimport urllib2\nfrom bs4 import BeautifulSoup\n\n# アクセスするURL\nurl = \u0026amp;quot;http://www.nikkei.com/markets/kabu/\u0026amp;quot;\n\n# URLにアクセスする htmlが帰ってくる → \u0026amp;lt;html\u0026amp;gt;\u0026amp;lt;head\u0026amp;gt;\u0026amp;lt;title\u0026amp;gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026amp;lt;/title\u0026amp;gt;\u0026amp;lt;/head\u0026amp;gt;\u0026amp;lt;body....\nhtml = urllib2.urlopen(url)\n\n# htmlをBeautifulSoupで扱う\nsoup = BeautifulSoup(html, \u0026amp;quot;html.parser\u0026amp;quot;)\n\n# span要素全てを摘出する→全てのspan要素が配列に入ってかえされます→[\u0026amp;lt;span class=\u0026amp;quot;m-wficon triDown\u0026amp;quot;\u0026amp;gt;\u0026amp;lt;/span\u0026amp;gt;, \u0026amp;lt;span class=\u0026amp;quot;l-h...\nspan = soup.find_all(\u0026amp;quot;span\u0026amp;quot;)\n\n# print時のエラーとならないように最初に宣言しておきます。\nnikkei_heikin = \u0026amp;quot;\u0026amp;quot;\n# for分で全てのspan要素の中からClass=\u0026amp;quot;mkc-stock_prices\u0026amp;quot;となっている物を探します\nfor tag in span:\n    # classの設定がされていない要素は、tag.get(\u0026amp;quot;class\u0026amp;quot;).pop(0)を行うことのできないでエラーとなるため、tryでエラーを回避する\n    try:\n        # tagの中からclass=\u0026amp;quot;n\u0026amp;quot;のnの文字列を摘出します。複数classが設定されている場合があるので\n        # get関数では配列で帰ってくる。そのため配列の関数pop(0)により、配列の一番最初を摘出する\n        # \u0026amp;lt;span class=\u0026amp;quot;hoge\u0026amp;quot; class=\u0026amp;quot;foo\u0026amp;quot;\u0026amp;gt;  →   [\u0026amp;quot;hoge\u0026amp;quot;,\u0026amp;quot;foo\u0026amp;quot;]  →   hoge\n        string_ = tag.get(\u0026amp;quot;class\u0026amp;quot;).pop(0)\n\n        # 摘出したclassの文字列にmkc-stock_pricesと設定されているかを調べます\n        if string_ in \u0026amp;quot;mkc-stock_prices\u0026amp;quot;:\n            # mkc-stock_pricesが設定されているのでtagで囲まれた文字列を.stringであぶり出します\n            nikkei_heikin = tag.string\n            # 摘出が完了したのでfor分を抜けます\n            break\n    except:\n        # パス→何も処理を行わない\n        pass\n\n# 摘出した日経平均株価を出力します。\nprint nikkei_heikin\n```\n\n結果\n\n```shell.sh\n$ python getNikeiHeikin.py\n\u0026amp;gt;\u0026amp;gt;18,513.12\n```\n\n\nコードの解説は基本的にコメントにて挿入しています\n\n流れを簡単に表すと\n\n1.日本経済新聞\u0026amp;gt;マーケット\u0026amp;gt;株にアクセスをし、HTMLを拾ってくる\n2.日経平均株価はspan要素で囲ってあるので、HTML内部全てのspan要素を摘出する\n3.span要素に一つ一つをfor分で\u0026amp;quot;mkc-stock_prices\u0026amp;quot;がclassに設定されているかを確かめます\n4.設定されているclass見つかったら.stringで値を取得し、for分を終了\n5.取得した値をプリントする\n\nって流れです。\n\nこのプログラムの流れはだいたいの場面で使用することができます\nメリットとしては、そこまで難しくはなく、だいたいの場面で応用が利くことです\n注意点としはspan要素から別の要素に変わったり、classの内容の変わってしまうと出力することができません。\n\n### 繰り返しとcsv出力\n\nこの結果をcsvに出力し、一時間ごとに繰り返していきます\n\n```getNikeiHeikin.py\n# coding: UTF-8\nimport urllib2\nfrom bs4 import BeautifulSoup\nfrom datetime import datetime\nimport csv\nimport time\n\ntime_flag = True\n\n# 永久に実行させます\nwhile True:\n    # 時間が59分以外の場合は58秒間時間を待機する\n    if datetime.now().minute != 59:\n        # 59分ではないので1分(58秒)間待機します(誤差がないとは言い切れないので58秒です)\n        time.sleep(58)\n        continue\n    \n    # csvを追記モードで開きます→ここでcsvを開くのはファイルが大きくなった時にcsvを開くのに時間がかかるためです\n    f = open(\u0026amp;#39;nikkei_heikin.csv\u0026amp;#39;, \u0026amp;#39;a\u0026amp;#39;)\n    writer = csv.writer(f, lineterminator=\u0026amp;#39;\\n\u0026amp;#39;)\n\n    # 59分になりましたが正確な時間に測定をするために秒間隔で59秒になるまで抜け出せません\n    while datetime.now().second != 59:\n            # 00秒ではないので1秒待機\n            time.sleep(1)\n    # 処理が早く終わり二回繰り返してしまうのでここで一秒間待機します\n    time.sleep(1)\n\n    # csvに記述するレコードを作成します\n    csv_list = []\n\n    # 現在の時刻を年、月、日、時、分、秒で取得します\n    time_ = datetime.now().strftime(\u0026amp;quot;%Y/%m/%d %H:%M:%S\u0026amp;quot;)\n    # 1カラム目に時間を挿入します\n    csv_list.append(time_)\n\n    # アクセスするURL\n    url = \u0026amp;quot;http://www.nikkei.com/markets/kabu/\u0026amp;quot;\n\n    # URLにアクセスする htmlが帰ってくる → \u0026amp;lt;html\u0026amp;gt;\u0026amp;lt;head\u0026amp;gt;\u0026amp;lt;title\u0026amp;gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026amp;lt;/title\u0026amp;gt;\u0026amp;lt;/head\u0026amp;gt;\u0026amp;lt;body....\n    html = urllib2.urlopen(url)\n\n    # htmlをBeautifulSoupで扱う\n    soup = BeautifulSoup(html, \u0026amp;quot;html.parser\u0026amp;quot;)\n\n    # span要素全てを摘出する→全てのspan要素が配列に入ってかえされます→[\u0026amp;lt;span class=\u0026amp;quot;m-wficon triDown\u0026amp;quot;\u0026amp;gt;\u0026amp;lt;/span\u0026amp;gt;, \u0026amp;lt;span class=\u0026amp;quot;l-h...\n    span = soup.find_all(\u0026amp;quot;span\u0026amp;quot;)\n\n    # print時のエラーとならないように最初に宣言しておきます。\n    nikkei_heikin = \u0026amp;quot;\u0026amp;quot;\n    # for分で全てのspan要素の中からClass=\u0026amp;quot;mkc-stock_prices\u0026amp;quot;となっている物を探します\n    for tag in span:\n        # classの設定がされていない要素は、tag.get(\u0026amp;quot;class\u0026amp;quot;).pop(0)を行うことのできないでエラーとなるため、tryでエラーを回避する\n        try:\n            # tagの中からclass=\u0026amp;quot;n\u0026amp;quot;のnの文字列を摘出します。複数classが設定されている場合があるので\n            # get関数では配列で帰ってくる。そのため配列の関数pop(0)により、配列の一番最初を摘出する\n            # \u0026amp;lt;span class=\u0026amp;quot;hoge\u0026amp;quot; class=\u0026amp;quot;foo\u0026amp;quot;\u0026amp;gt;  →   [\u0026amp;quot;hoge\u0026amp;quot;,\u0026amp;quot;foo\u0026amp;quot;]  →   hoge\n            string_ = tag.get(\u0026amp;quot;class\u0026amp;quot;).pop(0)\n\n            # 摘出したclassの文字列にmkc-stock_pricesと設定されているかを調べます\n            if string_ in \u0026amp;quot;mkc-stock_prices\u0026amp;quot;:\n                # mkc-stock_pricesが設定されているのでtagで囲まれた文字列を.stringであぶり出します\n                nikkei_heikin = tag.string\n                # 摘出が完了したのでfor分を抜けます\n                break\n        except:\n            # パス→何も処理を行わない\n            pass\n\n    # 摘出した日経平均株価を時間とともに出力します。\n    print time_, nikkei_heikin\n    # 2カラム目に日経平均を記録します\n    csv_list.append(nikkei_heikin)\n    # csvに追記敷きます\n    writer.writerow(csv_list)\n    # ファイル破損防止のために閉じます\n    f.close()\n```\n\n流れ的には言えば\n1.n時00秒になるまで待機\n2.csvをオープン\n3.レコードを作成\n4.日経平均株価を取得\n5.レコードに追加\n6.レコードをcsvに書き込み\n\nってなわけです\n\nこれを実行し続けると一時間に一回アクセスを行い日経平均を取得し、記録してくれます。\n\nこれを応用すればなんだってできます\n\nたとえば、某南米の長い川でのセール時でのカート高速追加（俗に言うスクリプト勢）なんてできたり。。。\n\nあまりお勧めはしませんが\n\nでは！\n\n#### こちらもどうぞ\n[Python Webスクレイピング テクニック集「取得できない値は無い」JavaScript対応](https://qiita.com/Azunyan1111/items/b161b998790b1db2ff7a)\n[【毎秒1万リクエスト!?】Go言語で始める爆速Webスクレイピング【Golang】](https://qiita.com/Azunyan1111/items/a1b6c58dc868814efb51)\n[【初心者向け】Re:ゼロから始める遺伝的アルゴリズム【人工知能】](https://qiita.com/Azunyan1111/items/975c67129d99de33dc21)\n&quot;",
    td_title: "&quot;Python Webスクレイピング 実践入門&quot;"
  })</script><script async="" src="https://cdn.bigmining.com/private/js/qiita_bigmining.js"></script><div style="display:none"><div class="TagList__label"><span></span><span>Python</span></div><div class="TagList__label"><span></span><span>スクレイピング</span></div></div><img style="display:block;margin:0;padding:0;border:0;outline:0;width:0;height:0;line-height:0;" alt="" src="https://relay-dsp.ad-m.asia/dmp/sync/bizmatrix?pid=c3ed207b574cf11376&amp;d=x18o8hduaj&amp;uid=" /><script type="application/json" id="js-react-on-rails-context">{"railsEnv":"production","inMailer":false,"i18nLocale":"ja","i18nDefaultLocale":"en","href":"https://qiita.com/Azunyan1111/items/9b3d16428d2bcc7c9406","location":"/Azunyan1111/items/9b3d16428d2bcc7c9406","scheme":"https","host":"qiita.com","port":null,"pathname":"/Azunyan1111/items/9b3d16428d2bcc7c9406","search":null,"httpAcceptLanguage":"ja,en-US;q=0.9,en;q=0.8","actionPath":"public/items#show","settings":{"analyticsTrackingId":"UA-24675221-12","mixpanelToken":"17d24b448ca579c365d2d1057f3a1791","assetsMap":{},"csrfToken":"DBBKzIAl7QLpew383imKanhSgGLny6a+rn+l8jk98HMtuXUUhLaTP3FuvWwz/sGFqBHZG+8FRJPMpf5NGMPMWA==","locale":"ja"},"currentUser":null,"isLoggedIn":false,"serverSide":false}</script>
<div id="PersonalPublicArticle-react-component-471b5e90-b62f-41ca-b5bf-ad9042d32efe"><div class="p-items" itemscope="" itemType="http://schema.org/Article"><div class="p-items_wrapper"><div class="p-items_container"><div class="p-items_main"><div class="p-items_article"><div class="it-Header"><div class="u-flex-center-between mb-3"><div class="it-Header_info"><div class="it-Header_author"><a href="/Azunyan1111"><img src="https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2Fprofile-images%2F1535776100?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;lossless=0&amp;w=48&amp;s=ab8b67ebe7389304d51aed7504627ea6" alt="Azunyan1111" class="it-Header_authorImage"/></a><a href="/Azunyan1111" class="it-Header_authorName">@<!-- -->Azunyan1111</a></div><div class="it-Header_time"><span><meta content="2016-12-01T15:04:15Z" itemProp="datePublished"/><time dateTime="2018-02-23T09:56:13Z" itemProp="dateModified">2018年02月23日に更新</time></span></div><div class="it-Header_meta"><div class="it-Header_manipulate"><div class="it-Header_dropdown"><span class="it-Header_dropdownToggle" tabindex="0"><span class="fa fa-ellipsis-h fa-lg"></span></span><div class="st-Dropdown right"><div><div class="it-Header_dropdown-title">記事の改善</div><a class="st-Dropdown_item" href="/drafts/9b3d16428d2bcc7c9406/edit"><span class="fa fa-fw fa-code-fork pr-1"></span>編集リクエストを送る</a><div class="st-Dropdown_separator"></div></div><div class="it-Header_dropdown-title">記事の情報</div><a class="st-Dropdown_item" href="/Azunyan1111/items/9b3d16428d2bcc7c9406/revisions"><span class="fa fa-fw fa-history pr-1"></span>編集履歴</a><a class="st-Dropdown_item" href="/Azunyan1111/items/9b3d16428d2bcc7c9406/patches"><span class="fa fa-fw fa-inbox pr-1"></span>編集リクエスト一覧</a><a class="st-Dropdown_item" href="/Azunyan1111/items/9b3d16428d2bcc7c9406/likers"><span class="fa fa-fw fa-thumbs-up pr-1"></span>いいねしたユーザ一覧</a><a class="st-Dropdown_item" href="/Azunyan1111/items/9b3d16428d2bcc7c9406.md"><span class="fa fa-fw fa-file-text-o pr-1"></span>Markdown で本文を見る</a><div class="st-Dropdown_separator"></div><div class="st-Dropdown_item"><span class="fa fa-fw fa-flag pr-1"></span>問題がある記事を報告する</div></div></div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">この記事にどのような問題がありますか？</span></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>スパムです</label></div><div class="st-Form"><label><input type="radio" name="reason" value="harassment" required=""/>攻撃的または迷惑な内容を含んでいます</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>不適切な内容を含んでいます</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="送信"/></div></form></div></div></div></div></div><div class="it-AdcalRibbon"><span><a href="/advent-calendar/2016/crawler" class="it-AdcalRibbon_title">クローラー／Webスクレイピング<!-- --> Advent Calendar<!-- --> <!-- -->2016</a>2日目</span></div><h1 class="it-Header_title" itemProp="headline">Python Webスクレイピング 実践入門</h1><div class="it-Tags"><a href="/tags/python" class="it-Tags_item"><span>Python</span></a><a href="/tags/%e3%82%b9%e3%82%af%e3%83%ac%e3%82%a4%e3%83%94%e3%83%b3%e3%82%b0" class="it-Tags_item"><span>スクレイピング</span></a></div></div><div class="it-DeprecationAlert_one mb-5 p-2"><span class="fa fa-warning mr-1"></span>この記事は最終更新日から1年以上が経過しています。</div><section class="it-MdContent" itemProp="articleBody"><div id="personal-public-article-body"><div><p>PythonによるWebスクレイピングの実践入門を書きたいと思います。</p>

<p>概論的なところは除いて、フィーリングで理解していくスタイルで行きたいと思います。</p>

<p>※追記<br>
本記事は少し難しいやり方をとっていますが、学習すると言う意味ではとても価値あるものだと思います。<br>
本記事を読み終えた後はこちらのテクニック編わご覧になるとサクッと出来たりします。<br>
<a href="https://qiita.com/Azunyan1111/items/b161b998790b1db2ff7a" id="reference-9cc831c78f6631f796d0">Python Webスクレイピング テクニック集「取得できない値は無い」JavaScript対応</a></p>

<h2>
<span id="やること" class="fragment"></span><a href="#%E3%82%84%E3%82%8B%E3%81%93%E3%81%A8"><i class="fa fa-link"></i></a>やること</h2>

<p>最終的には「1時間ごとに日本経済新聞にアクセスを行いその時の日経平均株価をcsvに記録する」</p>

<p>プログラムを組んでみたいと思います。</p>

<h3>
<span id="注意" class="fragment"></span><a href="#%E6%B3%A8%E6%84%8F"><i class="fa fa-link"></i></a>注意</h3>

<p>注意事項です。よく読みましょう。<br>
<a href="https://ja.wikipedia.org/wiki/%E5%B2%A1%E5%B4%8E%E5%B8%82%E7%AB%8B%E4%B8%AD%E5%A4%AE%E5%9B%B3%E6%9B%B8%E9%A4%A8%E4%BA%8B%E4%BB%B6" rel="nofollow noopener" target="_blank">岡崎市立中央図書館事件(Librahack事件) - Wikipedia</a><br>
<a href="https://qiita.com/nezuq/items/c5e827e1827e7cb29011" id="reference-ab7a93636a2f8733d840">Webスクレイピングの注意事項一覧</a></p>

<h2>
<span id="何を使うの" class="fragment"></span><a href="#%E4%BD%95%E3%82%92%E4%BD%BF%E3%81%86%E3%81%AE"><i class="fa fa-link"></i></a>何を使うの？</h2>

<p>言語:Python 2.7.12<br>
ライブラリ:urllib2、BeautifulSoup、csv、datetime、time</p>

<p>urllib2はURLにアクセスするために必要です。<br>
BeautifulSoupはアクセスして取得したファイルを開くxmlパーサー的なものです<br>
csvファイルを操作する時に必要なライブラリです。<br>
datetimeは時間を取得するためのライブラリです</p>

<h2>
<span id="ライブラリインストール" class="fragment"></span><a href="#%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>ライブラリインストール</h2>

<p>urllib2はPythonをインストールするとインストールされてまいす。<br>
BeautifulSoupをインストールするにはpipコマンドを使います</p>

<div class="code-frame" data-lang="shell">
<div class="code-lang"><span class="bold">shell.sh</span></div>
<div class="highlight"><pre><span class="nv">$ </span>pip <span class="nb">install </span>beautifulsoup4
</pre></div>
</div>

<h3>
<span id="手始めに日本経済新聞のページタイトルを取得してみよう" class="fragment"></span><a href="#%E6%89%8B%E5%A7%8B%E3%82%81%E3%81%AB%E6%97%A5%E6%9C%AC%E7%B5%8C%E6%B8%88%E6%96%B0%E8%81%9E%E3%81%AE%E3%83%9A%E3%83%BC%E3%82%B8%E3%82%BF%E3%82%A4%E3%83%88%E3%83%AB%E3%82%92%E5%8F%96%E5%BE%97%E3%81%97%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86"><i class="fa fa-link"></i></a>手始めに日本経済新聞のページタイトルを取得してみよう！</h3>

<p>まず手始めに日本経済新聞にPythonにてアクセスを行い、そのHTMLを取得します。</p>

<p>そのあとにBeautifulSoupで扱える形にし、</p>

<p>その扱える形からページタイトルを取得し、出力します。</p>

<p>また、今回はページのタイトルだけを取得するとイメージがわきにくいかもしれないので、title要素を入手し、タイトル要素の中からタイトルを取得したいと思います。</p>

<div class="code-frame" data-lang="python">
<div class="code-lang"><span class="bold">getNikkeiWebPageTitle.py</span></div>
<div class="highlight"><pre><span class="c1"># coding: UTF-8
</span><span class="kn">import</span> <span class="nn">urllib2</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="c1"># アクセスするURL
</span><span class="n">url</span> <span class="o">=</span> <span class="s">"http://www.nikkei.com/"</span>

<span class="c1"># URLにアクセスする htmlが帰ってくる → &lt;html&gt;&lt;head&gt;&lt;title&gt;経済、株価、ビジネス、政治のニュース:日経電子版&lt;/title&gt;&lt;/head&gt;&lt;body....
</span><span class="n">html</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="c1"># htmlをBeautifulSoupで扱う
</span><span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>

<span class="c1"># タイトル要素を取得する → &lt;title&gt;経済、株価、ビジネス、政治のニュース:日経電子版&lt;/title&gt;
</span><span class="n">title_tag</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">title</span>

<span class="c1"># 要素の文字列を取得する → 経済、株価、ビジネス、政治のニュース:日経電子版
</span><span class="n">title</span> <span class="o">=</span> <span class="n">title_tag</span><span class="o">.</span><span class="n">string</span>

<span class="c1"># タイトル要素を出力
</span><span class="k">print</span> <span class="n">title_tag</span>

<span class="c1"># タイトルを文字列を出力
</span><span class="k">print</span> <span class="n">title</span>

</pre></div>
</div>

<p>これを実行すると下記の結果が返ってきます。</p>

<div class="code-frame" data-lang="shell">
<div class="code-lang"><span class="bold">shell.sh</span></div>
<div class="highlight"><pre><span class="nv">$ </span>python getNikkeiWebPageTitle.py
&lt;title&gt;経済、株価、ビジネス、政治のニュース:日経電子版&lt;/title&gt;
経済、株価、ビジネス、政治のニュース:日経電子版
</pre></div>
</div>

<p>ちなみに</p>

<div class="code-frame" data-lang="python">
<div class="code-lang"><span class="bold">print.py</span></div>
<div class="highlight"><pre><span class="k">print</span> <span class="n">soup</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">string</span>
</pre></div>
</div>

<p>この場合でも同様の結果を得られます。</p>

<p>これで大体のイメージをつかめたと思います。</p>

<h2>
<span id="実践" class="fragment"></span><a href="#%E5%AE%9F%E8%B7%B5"><i class="fa fa-link"></i></a>実践！</h2>

<p>今回の目標は「1時間ごとに日本経済新聞にアクセスを行いその時の日経平均株価をcsvに記録する」と言うことです。<br>
フログラム手順を確認すると</p>

<p>1.日本経済新聞の日経平均株価ページにアクセスし、HTMLを取得する<br>
3.BeautifulSoupを使い日経平均株価を取得する<br>
4.csvに日付と時間と日経平均株価の値を1レコードで記述する</p>

<p>csvに関してはHeaderは使用しません。</p>

<p>ではではやってみましょう。</p>

<h3>
<span id="日経平均株価ページへアクセス" class="fragment"></span><a href="#%E6%97%A5%E7%B5%8C%E5%B9%B3%E5%9D%87%E6%A0%AA%E4%BE%A1%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%B8%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9"><i class="fa fa-link"></i></a>日経平均株価ページへアクセス</h3>

<p>まず始めに日経平均株価のページへアクセスします。</p>

<p>URLはあらかじめブラウザから自分で調べるのがセオリーですね</p>

<p>調べると「日本経済新聞→マーケット→株」のページにありますね</p>

<p>先ほどのプラグラムを流用します</p>

<div class="code-frame" data-lang="python">
<div class="code-lang"><span class="bold">getNikkeiHeikin.py</span></div>
<div class="highlight"><pre><span class="c1"># coding: UTF-8
</span><span class="kn">import</span> <span class="nn">urllib2</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="c1"># アクセスするURL
</span><span class="n">url</span> <span class="o">=</span> <span class="s">"http://www.nikkei.com/markets/kabu/"</span>

<span class="c1"># URLにアクセスする htmlが帰ってくる → &lt;html&gt;&lt;head&gt;&lt;title&gt;経済、株価、ビジネス、政治のニュース:日経電子版&lt;/title&gt;&lt;/head&gt;&lt;body....
</span><span class="n">html</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="c1"># htmlをBeautifulSoupで扱う
</span><span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>

<span class="c1"># タイトルを文字列を出力
</span><span class="k">print</span> <span class="n">soup</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">string</span>
</pre></div>
</div>

<p>これによりタイトルが出力されます。</p>

<div class="code-frame" data-lang="shell">
<div class="code-lang"><span class="bold">shell.sh</span></div>
<div class="highlight"><pre><span class="nv">$ </span>python getNikkiHeikin.py
<span class="o">&gt;&gt;</span>株式　：マーケット　：日経電子版
</pre></div>
</div>

<h3>
<span id="日経平均株価取得" class="fragment"></span><a href="#%E6%97%A5%E7%B5%8C%E5%B9%B3%E5%9D%87%E6%A0%AA%E4%BE%A1%E5%8F%96%E5%BE%97"><i class="fa fa-link"></i></a>日経平均株価取得</h3>

<p>次に日経平均株価を取得します。</p>

<p>ブラウザで<a href="http://www.nikkei.com/markets/kabu/" rel="nofollow noopener" target="_blank">日本経済新聞&gt;マーケット&gt;株</a>を開いてみましょう</p>

<p>このページの一番上から少し下のほうに日経平均株価が載っています。</p>

<p>これを取得するには、このデータのHTML上での位置を探る必要があります。</p>

<p>日経平均株価を右クリックして、「検証」を押しましょう。</p>

<p>するとこのような画面になると思います</p>

<p><a href="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2F62c26aaf-fe38-6e19-4a45-edca703726d7.png?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;gif-q=60&amp;s=4e5560966bef9a39f63974c5e56250a0" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2F62c26aaf-fe38-6e19-4a45-edca703726d7.png?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;gif-q=60&amp;s=4e5560966bef9a39f63974c5e56250a0" alt="スクリーンショット 2016-12-01 17.59.17.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/110135/62c26aaf-fe38-6e19-4a45-edca703726d7.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2F62c26aaf-fe38-6e19-4a45-edca703726d7.png?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;gif-q=60&amp;w=1400&amp;fit=max&amp;s=1a415b508826ff4580ea50f30e3c39d3 1x" loading="lazy"></a></p>

<p>span要素でClass="mkc-stock_prices"となっています。</p>

<p>これで位置がわかりました。</p>

<p>では実際にBeautifulSoupでprintしてみましょう。</p>

<div class="code-frame" data-lang="python">
<div class="code-lang"><span class="bold">getNikeiHeikin.py</span></div>
<div class="highlight"><pre><span class="c1"># coding: UTF-8
</span><span class="kn">import</span> <span class="nn">urllib2</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="c1"># アクセスするURL
</span><span class="n">url</span> <span class="o">=</span> <span class="s">"http://www.nikkei.com/markets/kabu/"</span>

<span class="c1"># URLにアクセスする htmlが帰ってくる → &lt;html&gt;&lt;head&gt;&lt;title&gt;経済、株価、ビジネス、政治のニュース:日経電子版&lt;/title&gt;&lt;/head&gt;&lt;body....
</span><span class="n">html</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="c1"># htmlをBeautifulSoupで扱う
</span><span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>

<span class="c1"># span要素全てを摘出する→全てのspan要素が配列に入ってかえされます→[&lt;span class="m-wficon triDown"&gt;&lt;/span&gt;, &lt;span class="l-h...
</span><span class="n">span</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">"span"</span><span class="p">)</span>

<span class="c1"># print時のエラーとならないように最初に宣言しておきます。
</span><span class="n">nikkei_heikin</span> <span class="o">=</span> <span class="s">""</span>
<span class="c1"># for分で全てのspan要素の中からClass="mkc-stock_prices"となっている物を探します
</span><span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">span</span><span class="p">:</span>
    <span class="c1"># classの設定がされていない要素は、tag.get("class").pop(0)を行うことのできないでエラーとなるため、tryでエラーを回避する
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># tagの中からclass="n"のnの文字列を摘出します。複数classが設定されている場合があるので
</span>        <span class="c1"># get関数では配列で帰ってくる。そのため配列の関数pop(0)により、配列の一番最初を摘出する
</span>        <span class="c1"># &lt;span class="hoge" class="foo"&gt;  →   ["hoge","foo"]  →   hoge
</span>        <span class="n">string_</span> <span class="o">=</span> <span class="n">tag</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># 摘出したclassの文字列にmkc-stock_pricesと設定されているかを調べます
</span>        <span class="k">if</span> <span class="n">string_</span> <span class="ow">in</span> <span class="s">"mkc-stock_prices"</span><span class="p">:</span>
            <span class="c1"># mkc-stock_pricesが設定されているのでtagで囲まれた文字列を.stringであぶり出します
</span>            <span class="n">nikkei_heikin</span> <span class="o">=</span> <span class="n">tag</span><span class="o">.</span><span class="n">string</span>
            <span class="c1"># 摘出が完了したのでfor分を抜けます
</span>            <span class="k">break</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="c1"># パス→何も処理を行わない
</span>        <span class="k">pass</span>

<span class="c1"># 摘出した日経平均株価を出力します。
</span><span class="k">print</span> <span class="n">nikkei_heikin</span>
</pre></div>
</div>

<p>結果</p>

<div class="code-frame" data-lang="shell">
<div class="code-lang"><span class="bold">shell.sh</span></div>
<div class="highlight"><pre><span class="nv">$ </span>python getNikeiHeikin.py
<span class="o">&gt;&gt;</span>18,513.12
</pre></div>
</div>

<p>コードの解説は基本的にコメントにて挿入しています</p>

<p>流れを簡単に表すと</p>

<p>1.日本経済新聞&gt;マーケット&gt;株にアクセスをし、HTMLを拾ってくる<br>
2.日経平均株価はspan要素で囲ってあるので、HTML内部全てのspan要素を摘出する<br>
3.span要素に一つ一つをfor分で"mkc-stock_prices"がclassに設定されているかを確かめます<br>
4.設定されているclass見つかったら.stringで値を取得し、for分を終了<br>
5.取得した値をプリントする</p>

<p>って流れです。</p>

<p>このプログラムの流れはだいたいの場面で使用することができます<br>
メリットとしては、そこまで難しくはなく、だいたいの場面で応用が利くことです<br>
注意点としはspan要素から別の要素に変わったり、classの内容の変わってしまうと出力することができません。</p>

<h3>
<span id="繰り返しとcsv出力" class="fragment"></span><a href="#%E7%B9%B0%E3%82%8A%E8%BF%94%E3%81%97%E3%81%A8csv%E5%87%BA%E5%8A%9B"><i class="fa fa-link"></i></a>繰り返しとcsv出力</h3>

<p>この結果をcsvに出力し、一時間ごとに繰り返していきます</p>

<div class="code-frame" data-lang="python">
<div class="code-lang"><span class="bold">getNikeiHeikin.py</span></div>
<div class="highlight"><pre><span class="c1"># coding: UTF-8
</span><span class="kn">import</span> <span class="nn">urllib2</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">time_flag</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># 永久に実行させます
</span><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="c1"># 時間が59分以外の場合は58秒間時間を待機する
</span>    <span class="k">if</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">minute</span> <span class="o">!=</span> <span class="mi">59</span><span class="p">:</span>
        <span class="c1"># 59分ではないので1分(58秒)間待機します(誤差がないとは言い切れないので58秒です)
</span>        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">58</span><span class="p">)</span>
        <span class="k">continue</span>

    <span class="c1"># csvを追記モードで開きます→ここでcsvを開くのはファイルが大きくなった時にcsvを開くのに時間がかかるためです
</span>    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">'nikkei_heikin.csv'</span><span class="p">,</span> <span class="s">'a'</span><span class="p">)</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">lineterminator</span><span class="o">=</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

    <span class="c1"># 59分になりましたが正確な時間に測定をするために秒間隔で59秒になるまで抜け出せません
</span>    <span class="k">while</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">second</span> <span class="o">!=</span> <span class="mi">59</span><span class="p">:</span>
            <span class="c1"># 00秒ではないので1秒待機
</span>            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># 処理が早く終わり二回繰り返してしまうのでここで一秒間待機します
</span>    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># csvに記述するレコードを作成します
</span>    <span class="n">csv_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># 現在の時刻を年、月、日、時、分、秒で取得します
</span>    <span class="n">time_</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">Y/</span><span class="si">%</span><span class="s">m/</span><span class="si">%</span><span class="s">d </span><span class="si">%</span><span class="s">H:</span><span class="si">%</span><span class="s">M:</span><span class="si">%</span><span class="s">S"</span><span class="p">)</span>
    <span class="c1"># 1カラム目に時間を挿入します
</span>    <span class="n">csv_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time_</span><span class="p">)</span>

    <span class="c1"># アクセスするURL
</span>    <span class="n">url</span> <span class="o">=</span> <span class="s">"http://www.nikkei.com/markets/kabu/"</span>

    <span class="c1"># URLにアクセスする htmlが帰ってくる → &lt;html&gt;&lt;head&gt;&lt;title&gt;経済、株価、ビジネス、政治のニュース:日経電子版&lt;/title&gt;&lt;/head&gt;&lt;body....
</span>    <span class="n">html</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="c1"># htmlをBeautifulSoupで扱う
</span>    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>

    <span class="c1"># span要素全てを摘出する→全てのspan要素が配列に入ってかえされます→[&lt;span class="m-wficon triDown"&gt;&lt;/span&gt;, &lt;span class="l-h...
</span>    <span class="n">span</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">"span"</span><span class="p">)</span>

    <span class="c1"># print時のエラーとならないように最初に宣言しておきます。
</span>    <span class="n">nikkei_heikin</span> <span class="o">=</span> <span class="s">""</span>
    <span class="c1"># for分で全てのspan要素の中からClass="mkc-stock_prices"となっている物を探します
</span>    <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">span</span><span class="p">:</span>
        <span class="c1"># classの設定がされていない要素は、tag.get("class").pop(0)を行うことのできないでエラーとなるため、tryでエラーを回避する
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># tagの中からclass="n"のnの文字列を摘出します。複数classが設定されている場合があるので
</span>            <span class="c1"># get関数では配列で帰ってくる。そのため配列の関数pop(0)により、配列の一番最初を摘出する
</span>            <span class="c1"># &lt;span class="hoge" class="foo"&gt;  →   ["hoge","foo"]  →   hoge
</span>            <span class="n">string_</span> <span class="o">=</span> <span class="n">tag</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># 摘出したclassの文字列にmkc-stock_pricesと設定されているかを調べます
</span>            <span class="k">if</span> <span class="n">string_</span> <span class="ow">in</span> <span class="s">"mkc-stock_prices"</span><span class="p">:</span>
                <span class="c1"># mkc-stock_pricesが設定されているのでtagで囲まれた文字列を.stringであぶり出します
</span>                <span class="n">nikkei_heikin</span> <span class="o">=</span> <span class="n">tag</span><span class="o">.</span><span class="n">string</span>
                <span class="c1"># 摘出が完了したのでfor分を抜けます
</span>                <span class="k">break</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="c1"># パス→何も処理を行わない
</span>            <span class="k">pass</span>

    <span class="c1"># 摘出した日経平均株価を時間とともに出力します。
</span>    <span class="k">print</span> <span class="n">time_</span><span class="p">,</span> <span class="n">nikkei_heikin</span>
    <span class="c1"># 2カラム目に日経平均を記録します
</span>    <span class="n">csv_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nikkei_heikin</span><span class="p">)</span>
    <span class="c1"># csvに追記敷きます
</span>    <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">csv_list</span><span class="p">)</span>
    <span class="c1"># ファイル破損防止のために閉じます
</span>    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>

<p>流れ的には言えば<br>
1.n時00秒になるまで待機<br>
2.csvをオープン<br>
3.レコードを作成<br>
4.日経平均株価を取得<br>
5.レコードに追加<br>
6.レコードをcsvに書き込み</p>

<p>ってなわけです</p>

<p>これを実行し続けると一時間に一回アクセスを行い日経平均を取得し、記録してくれます。</p>

<p>これを応用すればなんだってできます</p>

<p>たとえば、某南米の長い川でのセール時でのカート高速追加（俗に言うスクリプト勢）なんてできたり。。。</p>

<p>あまりお勧めはしませんが</p>

<p>では！</p>

<h4>
<span id="こちらもどうぞ" class="fragment"></span><a href="#%E3%81%93%E3%81%A1%E3%82%89%E3%82%82%E3%81%A9%E3%81%86%E3%81%9E"><i class="fa fa-link"></i></a>こちらもどうぞ</h4>

<p><a href="https://qiita.com/Azunyan1111/items/b161b998790b1db2ff7a">Python Webスクレイピング テクニック集「取得できない値は無い」JavaScript対応</a><br>
<a href="https://qiita.com/Azunyan1111/items/a1b6c58dc868814efb51" id="reference-21867ef0d32eeceb5922">【毎秒1万リクエスト!?】Go言語で始める爆速Webスクレイピング【Golang】</a><br>
<a href="https://qiita.com/Azunyan1111/items/975c67129d99de33dc21" id="reference-4b273e5ea4c5a09074c6">【初心者向け】Re:ゼロから始める遺伝的アルゴリズム【人工知能】</a></p>
</div></div></section><div class="it-Footer"><div class="it-Footer_actions"><div class="it-Footer_editRequest"><a href="/drafts/9b3d16428d2bcc7c9406/edit" class="u-link-no-underline"><span class="fa fa-fw fa-code-fork"></span><span>編集リクエスト</span></a></div><div class="it-Footer_stock"><button><span class="fa fa-folder-open"></span><span class="it-Footer_stockLabel">ストック</span></button></div><div class="it-Footer_like"><button><span class="fa fa-fw fa-thumbs-up"></span><span>いいね</span></button><a href="/Azunyan1111/items/9b3d16428d2bcc7c9406/likers" class="it-Footer_likeCount">1150</a></div></div><div class="it-Footer_social"><div class="it-Footer_shareButton it-Footer_shareButton-twitter"><span class="fa fa-twitter"></span></div><div class="it-Footer_shareButton it-Footer_shareButton-facebook"><span class="fa fa-facebook"></span></div></div></div><div class="ai-Container" itemProp="author" itemscope="" itemType="http://schema.org/Person"><div class="ai-User"><a href="/Azunyan1111"><img src="https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2Fprofile-images%2F1535776100?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;lossless=0&amp;w=75&amp;s=c22b90166a09de5356165601b447702d" alt="Azunyan1111" class="ai-User_image" itemProp="image"/></a><div class="ai-User_body"><div class="ai-User_header"><a href="/Azunyan1111" class="ai-User_name"></a><a href="/Azunyan1111" class="ai-User_urlname" itemProp="name">@<!-- -->Azunyan1111</a><span itemProp="memberOf" itemscope="" itemType="http://schema.org/Organization"><a href="/organizations/naxa" itemProp="url"><img src="https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/89af7512122455dd63dad532b508af9a99523593/original.jpg?1571198423" alt="naxa" class="ai-User_organization" itemProp="image"/></a></span></div><div class="ai-User_description">#seccamp 18 18Y 16F/Golang/Webセキュリティ/サイバー犯罪/Tor研究＆Torサービス運営/ゲーム会社</div><a href="https://blog.azunyan1111.com/" class="ai-User_website">https://blog.azunyan1111.com/</a><div class="ai-User_footer"><button class="it-UserFollowButton it-UserFollowButton-follow">フォロー</button></div></div></div><div class="ai-Organization" itemProp="memberOf" itemscope="" itemType="http://schema.org/Organization"><a href="/organizations/naxa" itemProp="url"><img src="https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/89af7512122455dd63dad532b508af9a99523593/original.jpg?1571198423" alt="naxa" class="ai-Organization_image" itemProp="image"/></a><div class="ai-Organization_body"><div class="ai-Organization_header"><a href="/organizations/naxa" class="ai-Organization_name"><span itemProp="legalName">合同会社ナクサ</span></a></div><div class="ai-Organization_description" itemProp="description">弊社では、ウェブアプリケーションのサーバサイド、アプリ、インフラにおける受託開発やコンサルティングをお受けしています。</div><a href="https://www.naxa.co.jp" class="ai-Organization_website">https://www.naxa.co.jp</a></div></div></div><div class="apm-Content"><div class="apm-Content_title">ユーザー登録して、Qiitaをもっと便利に使ってみませんか。</div><ol class="apm-Content_list"><li>あなたにマッチした記事をお届けします<div class="description">ユーザーやタグをフォローすることで、あなたが興味を持つ技術分野の情報をまとめてキャッチアップできます</div></li><li>便利な情報をあとで効率的に読み返せます<div class="description">気に入った記事を「ストック」することで、あとからすぐに検索できます</div></li><div><a class="apm-Content_help" href="https://help.qiita.com/ja/articles/qiita-login-user" target="_blank"><i class="fa fa-fw fa-arrow-circle-right"></i>より詳しく</a></div></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2FAzunyan1111%2Fitems%2F9b3d16428d2bcc7c9406&amp;realm=qiita" class="apm-Content_button apm-Content_button-signup">登録する</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2FAzunyan1111%2Fitems%2F9b3d16428d2bcc7c9406&amp;realm=qiita" class="apm-Content_button apm-Content_button-signin">ログインする</a></div></div></div><div class="p-items_options"><div class="mt-2"></div></div><div class="p-items_toc"><div class="mt-2"></div></div></div></div><div class="p-items_wrapper p-items_wrapper-white"><div class="p-items_container"><div class="p-items_leftDummy"></div><div class="p-items_main"><div class="p-items_aside px-5 p-2@s"><div id="logly-lift-4279493"><div class="tl-DummyItemList p-2"><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div></div></div></div><div class="p-items_aside mt-5 px-5 p-2@s"></div><div></div><div class="p-items_aside mt-6 px-5 p-2@s" id="comments-wrapper"><div id="comments" class="co-ItemWrapper"><div class="co-ItemWrapper_title mb-2"><span class="fa fa-comments mr-1"></span>コメント</div><div class="co-AnonymousForm p-3"><div class="co-AnonymousForm_title mb-1">あなたもコメントしてみませんか :)</div><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2FAzunyan1111%2Fitems%2F9b3d16428d2bcc7c9406&amp;realm=qiita" class="co-AnonymousForm_signup">ユーザ登録</a><div class="co-AnonymousForm_sub mt-1">すでにアカウントを持っている方は<a href="/login?callback_action=login_or_signup&amp;redirect_to=%2FAzunyan1111%2Fitems%2F9b3d16428d2bcc7c9406&amp;realm=qiita" class="co-AnonymousForm_login">ログイン</a></div></div></div></div></div><div class="p-items_rightDummy"></div></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="PersonalPublicArticle" data-dom-id="PersonalPublicArticle-react-component-471b5e90-b62f-41ca-b5bf-ad9042d32efe">{"article":{"body":"\u003cp\u003ePythonによるWebスクレイピングの実践入門を書きたいと思います。\u003c/p\u003e\n\n\u003cp\u003e概論的なところは除いて、フィーリングで理解していくスタイルで行きたいと思います。\u003c/p\u003e\n\n\u003cp\u003e※追記\u003cbr\u003e\n本記事は少し難しいやり方をとっていますが、学習すると言う意味ではとても価値あるものだと思います。\u003cbr\u003e\n本記事を読み終えた後はこちらのテクニック編わご覧になるとサクッと出来たりします。\u003cbr\u003e\n\u003ca href=\"https://qiita.com/Azunyan1111/items/b161b998790b1db2ff7a\" id=\"reference-9cc831c78f6631f796d0\"\u003ePython Webスクレイピング テクニック集「取得できない値は無い」JavaScript対応\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"やること\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%84%E3%82%8B%E3%81%93%E3%81%A8\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eやること\u003c/h2\u003e\n\n\u003cp\u003e最終的には「1時間ごとに日本経済新聞にアクセスを行いその時の日経平均株価をcsvに記録する」\u003c/p\u003e\n\n\u003cp\u003eプログラムを組んでみたいと思います。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"注意\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%B3%A8%E6%84%8F\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e注意\u003c/h3\u003e\n\n\u003cp\u003e注意事項です。よく読みましょう。\u003cbr\u003e\n\u003ca href=\"https://ja.wikipedia.org/wiki/%E5%B2%A1%E5%B4%8E%E5%B8%82%E7%AB%8B%E4%B8%AD%E5%A4%AE%E5%9B%B3%E6%9B%B8%E9%A4%A8%E4%BA%8B%E4%BB%B6\" rel=\"nofollow noopener\" target=\"_blank\"\u003e岡崎市立中央図書館事件(Librahack事件) - Wikipedia\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://qiita.com/nezuq/items/c5e827e1827e7cb29011\" id=\"reference-ab7a93636a2f8733d840\"\u003eWebスクレイピングの注意事項一覧\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"何を使うの\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E4%BD%95%E3%82%92%E4%BD%BF%E3%81%86%E3%81%AE\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e何を使うの？\u003c/h2\u003e\n\n\u003cp\u003e言語:Python 2.7.12\u003cbr\u003e\nライブラリ:urllib2、BeautifulSoup、csv、datetime、time\u003c/p\u003e\n\n\u003cp\u003eurllib2はURLにアクセスするために必要です。\u003cbr\u003e\nBeautifulSoupはアクセスして取得したファイルを開くxmlパーサー的なものです\u003cbr\u003e\ncsvファイルを操作する時に必要なライブラリです。\u003cbr\u003e\ndatetimeは時間を取得するためのライブラリです\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"ライブラリインストール\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eライブラリインストール\u003c/h2\u003e\n\n\u003cp\u003eurllib2はPythonをインストールするとインストールされてまいす。\u003cbr\u003e\nBeautifulSoupをインストールするにはpipコマンドを使います\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"shell\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003eshell.sh\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003ebeautifulsoup4\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"手始めに日本経済新聞のページタイトルを取得してみよう\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%89%8B%E5%A7%8B%E3%82%81%E3%81%AB%E6%97%A5%E6%9C%AC%E7%B5%8C%E6%B8%88%E6%96%B0%E8%81%9E%E3%81%AE%E3%83%9A%E3%83%BC%E3%82%B8%E3%82%BF%E3%82%A4%E3%83%88%E3%83%AB%E3%82%92%E5%8F%96%E5%BE%97%E3%81%97%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e手始めに日本経済新聞のページタイトルを取得してみよう！\u003c/h3\u003e\n\n\u003cp\u003eまず手始めに日本経済新聞にPythonにてアクセスを行い、そのHTMLを取得します。\u003c/p\u003e\n\n\u003cp\u003eそのあとにBeautifulSoupで扱える形にし、\u003c/p\u003e\n\n\u003cp\u003eその扱える形からページタイトルを取得し、出力します。\u003c/p\u003e\n\n\u003cp\u003eまた、今回はページのタイトルだけを取得するとイメージがわきにくいかもしれないので、title要素を入手し、タイトル要素の中からタイトルを取得したいと思います。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003egetNikkeiWebPageTitle.py\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"c1\"\u003e# coding: UTF-8\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eurllib2\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ebs4\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# アクセスするURL\n\u003c/span\u003e\u003cspan class=\"n\"\u003eurl\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"http://www.nikkei.com/\"\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# URLにアクセスする htmlが帰ってくる → \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body....\n\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eurllib2\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eurlopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# htmlをBeautifulSoupで扱う\n\u003c/span\u003e\u003cspan class=\"n\"\u003esoup\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"html.parser\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# タイトル要素を取得する → \u0026lt;title\u0026gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026lt;/title\u0026gt;\n\u003c/span\u003e\u003cspan class=\"n\"\u003etitle_tag\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esoup\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etitle\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 要素の文字列を取得する → 経済、株価、ビジネス、政治のニュース:日経電子版\n\u003c/span\u003e\u003cspan class=\"n\"\u003etitle\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etitle_tag\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# タイトル要素を出力\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e \u003cspan class=\"n\"\u003etitle_tag\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# タイトルを文字列を出力\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e \u003cspan class=\"n\"\u003etitle\u003c/span\u003e\n\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003eこれを実行すると下記の結果が返ってきます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"shell\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003eshell.sh\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003epython getNikkeiWebPageTitle.py\n\u0026lt;title\u0026gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026lt;/title\u0026gt;\n経済、株価、ビジネス、政治のニュース:日経電子版\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003eちなみに\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003eprint.py\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e \u003cspan class=\"n\"\u003esoup\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etitle\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003eこの場合でも同様の結果を得られます。\u003c/p\u003e\n\n\u003cp\u003eこれで大体のイメージをつかめたと思います。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"実践\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E8%B7%B5\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実践！\u003c/h2\u003e\n\n\u003cp\u003e今回の目標は「1時間ごとに日本経済新聞にアクセスを行いその時の日経平均株価をcsvに記録する」と言うことです。\u003cbr\u003e\nフログラム手順を確認すると\u003c/p\u003e\n\n\u003cp\u003e1.日本経済新聞の日経平均株価ページにアクセスし、HTMLを取得する\u003cbr\u003e\n3.BeautifulSoupを使い日経平均株価を取得する\u003cbr\u003e\n4.csvに日付と時間と日経平均株価の値を1レコードで記述する\u003c/p\u003e\n\n\u003cp\u003ecsvに関してはHeaderは使用しません。\u003c/p\u003e\n\n\u003cp\u003eではではやってみましょう。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"日経平均株価ページへアクセス\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%97%A5%E7%B5%8C%E5%B9%B3%E5%9D%87%E6%A0%AA%E4%BE%A1%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%B8%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e日経平均株価ページへアクセス\u003c/h3\u003e\n\n\u003cp\u003eまず始めに日経平均株価のページへアクセスします。\u003c/p\u003e\n\n\u003cp\u003eURLはあらかじめブラウザから自分で調べるのがセオリーですね\u003c/p\u003e\n\n\u003cp\u003e調べると「日本経済新聞→マーケット→株」のページにありますね\u003c/p\u003e\n\n\u003cp\u003e先ほどのプラグラムを流用します\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003egetNikkeiHeikin.py\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"c1\"\u003e# coding: UTF-8\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eurllib2\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ebs4\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# アクセスするURL\n\u003c/span\u003e\u003cspan class=\"n\"\u003eurl\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"http://www.nikkei.com/markets/kabu/\"\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# URLにアクセスする htmlが帰ってくる → \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body....\n\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eurllib2\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eurlopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# htmlをBeautifulSoupで扱う\n\u003c/span\u003e\u003cspan class=\"n\"\u003esoup\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"html.parser\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# タイトルを文字列を出力\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e \u003cspan class=\"n\"\u003esoup\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etitle\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003eこれによりタイトルが出力されます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"shell\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003eshell.sh\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003epython getNikkiHeikin.py\n\u003cspan class=\"o\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e株式　：マーケット　：日経電子版\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"日経平均株価取得\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%97%A5%E7%B5%8C%E5%B9%B3%E5%9D%87%E6%A0%AA%E4%BE%A1%E5%8F%96%E5%BE%97\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e日経平均株価取得\u003c/h3\u003e\n\n\u003cp\u003e次に日経平均株価を取得します。\u003c/p\u003e\n\n\u003cp\u003eブラウザで\u003ca href=\"http://www.nikkei.com/markets/kabu/\" rel=\"nofollow noopener\" target=\"_blank\"\u003e日本経済新聞\u0026gt;マーケット\u0026gt;株\u003c/a\u003eを開いてみましょう\u003c/p\u003e\n\n\u003cp\u003eこのページの一番上から少し下のほうに日経平均株価が載っています。\u003c/p\u003e\n\n\u003cp\u003eこれを取得するには、このデータのHTML上での位置を探る必要があります。\u003c/p\u003e\n\n\u003cp\u003e日経平均株価を右クリックして、「検証」を押しましょう。\u003c/p\u003e\n\n\u003cp\u003eするとこのような画面になると思います\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2F62c26aaf-fe38-6e19-4a45-edca703726d7.png?ixlib=rb-1.2.2\u0026amp;auto=compress%2Cformat\u0026amp;gif-q=60\u0026amp;s=4e5560966bef9a39f63974c5e56250a0\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2F62c26aaf-fe38-6e19-4a45-edca703726d7.png?ixlib=rb-1.2.2\u0026amp;auto=compress%2Cformat\u0026amp;gif-q=60\u0026amp;s=4e5560966bef9a39f63974c5e56250a0\" alt=\"スクリーンショット 2016-12-01 17.59.17.png\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/110135/62c26aaf-fe38-6e19-4a45-edca703726d7.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2F62c26aaf-fe38-6e19-4a45-edca703726d7.png?ixlib=rb-1.2.2\u0026amp;auto=compress%2Cformat\u0026amp;gif-q=60\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=1a415b508826ff4580ea50f30e3c39d3 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003espan要素でClass=\"mkc-stock_prices\"となっています。\u003c/p\u003e\n\n\u003cp\u003eこれで位置がわかりました。\u003c/p\u003e\n\n\u003cp\u003eでは実際にBeautifulSoupでprintしてみましょう。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003egetNikeiHeikin.py\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"c1\"\u003e# coding: UTF-8\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eurllib2\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ebs4\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# アクセスするURL\n\u003c/span\u003e\u003cspan class=\"n\"\u003eurl\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"http://www.nikkei.com/markets/kabu/\"\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# URLにアクセスする htmlが帰ってくる → \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body....\n\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eurllib2\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eurlopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# htmlをBeautifulSoupで扱う\n\u003c/span\u003e\u003cspan class=\"n\"\u003esoup\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"html.parser\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# span要素全てを摘出する→全てのspan要素が配列に入ってかえされます→[\u0026lt;span class=\"m-wficon triDown\"\u0026gt;\u0026lt;/span\u0026gt;, \u0026lt;span class=\"l-h...\n\u003c/span\u003e\u003cspan class=\"n\"\u003espan\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esoup\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efind_all\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"span\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# print時のエラーとならないように最初に宣言しておきます。\n\u003c/span\u003e\u003cspan class=\"n\"\u003enikkei_heikin\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# for分で全てのspan要素の中からClass=\"mkc-stock_prices\"となっている物を探します\n\u003c/span\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003etag\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003espan\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# classの設定がされていない要素は、tag.get(\"class\").pop(0)を行うことのできないでエラーとなるため、tryでエラーを回避する\n\u003c/span\u003e    \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# tagの中からclass=\"n\"のnの文字列を摘出します。複数classが設定されている場合があるので\n\u003c/span\u003e        \u003cspan class=\"c1\"\u003e# get関数では配列で帰ってくる。そのため配列の関数pop(0)により、配列の一番最初を摘出する\n\u003c/span\u003e        \u003cspan class=\"c1\"\u003e# \u0026lt;span class=\"hoge\" class=\"foo\"\u0026gt;  →   [\"hoge\",\"foo\"]  →   hoge\n\u003c/span\u003e        \u003cspan class=\"n\"\u003estring_\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etag\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# 摘出したclassの文字列にmkc-stock_pricesと設定されているかを調べます\n\u003c/span\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003estring_\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"s\"\u003e\"mkc-stock_prices\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# mkc-stock_pricesが設定されているのでtagで囲まれた文字列を.stringであぶり出します\n\u003c/span\u003e            \u003cspan class=\"n\"\u003enikkei_heikin\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etag\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# 摘出が完了したのでfor分を抜けます\n\u003c/span\u003e            \u003cspan class=\"k\"\u003ebreak\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# パス→何も処理を行わない\n\u003c/span\u003e        \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 摘出した日経平均株価を出力します。\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e \u003cspan class=\"n\"\u003enikkei_heikin\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003e結果\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"shell\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003eshell.sh\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003epython getNikeiHeikin.py\n\u003cspan class=\"o\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e18,513.12\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003eコードの解説は基本的にコメントにて挿入しています\u003c/p\u003e\n\n\u003cp\u003e流れを簡単に表すと\u003c/p\u003e\n\n\u003cp\u003e1.日本経済新聞\u0026gt;マーケット\u0026gt;株にアクセスをし、HTMLを拾ってくる\u003cbr\u003e\n2.日経平均株価はspan要素で囲ってあるので、HTML内部全てのspan要素を摘出する\u003cbr\u003e\n3.span要素に一つ一つをfor分で\"mkc-stock_prices\"がclassに設定されているかを確かめます\u003cbr\u003e\n4.設定されているclass見つかったら.stringで値を取得し、for分を終了\u003cbr\u003e\n5.取得した値をプリントする\u003c/p\u003e\n\n\u003cp\u003eって流れです。\u003c/p\u003e\n\n\u003cp\u003eこのプログラムの流れはだいたいの場面で使用することができます\u003cbr\u003e\nメリットとしては、そこまで難しくはなく、だいたいの場面で応用が利くことです\u003cbr\u003e\n注意点としはspan要素から別の要素に変わったり、classの内容の変わってしまうと出力することができません。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"繰り返しとcsv出力\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%B9%B0%E3%82%8A%E8%BF%94%E3%81%97%E3%81%A8csv%E5%87%BA%E5%8A%9B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e繰り返しとcsv出力\u003c/h3\u003e\n\n\u003cp\u003eこの結果をcsvに出力し、一時間ごとに繰り返していきます\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003egetNikeiHeikin.py\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u003cspan class=\"c1\"\u003e# coding: UTF-8\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eurllib2\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ebs4\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edatetime\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edatetime\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ecsv\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etime\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etime_flag\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# 永久に実行させます\n\u003c/span\u003e\u003cspan class=\"k\"\u003ewhile\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# 時間が59分以外の場合は58秒間時間を待機する\n\u003c/span\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003edatetime\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eminute\u003c/span\u003e \u003cspan class=\"o\"\u003e!=\u003c/span\u003e \u003cspan class=\"mi\"\u003e59\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# 59分ではないので1分(58秒)間待機します(誤差がないとは言い切れないので58秒です)\n\u003c/span\u003e        \u003cspan class=\"n\"\u003etime\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esleep\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e58\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"k\"\u003econtinue\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# csvを追記モードで開きます→ここでcsvを開くのはファイルが大きくなった時にcsvを開くのに時間がかかるためです\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ef\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'nikkei_heikin.csv'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e'a'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ewriter\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecsv\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewriter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elineterminator\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 59分になりましたが正確な時間に測定をするために秒間隔で59秒になるまで抜け出せません\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ewhile\u003c/span\u003e \u003cspan class=\"n\"\u003edatetime\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esecond\u003c/span\u003e \u003cspan class=\"o\"\u003e!=\u003c/span\u003e \u003cspan class=\"mi\"\u003e59\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# 00秒ではないので1秒待機\n\u003c/span\u003e            \u003cspan class=\"n\"\u003etime\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esleep\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# 処理が早く終わり二回繰り返してしまうのでここで一秒間待機します\n\u003c/span\u003e    \u003cspan class=\"n\"\u003etime\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esleep\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# csvに記述するレコードを作成します\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ecsv_list\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 現在の時刻を年、月、日、時、分、秒で取得します\n\u003c/span\u003e    \u003cspan class=\"n\"\u003etime_\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edatetime\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enow\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estrftime\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e%\u003c/span\u003e\u003cspan class=\"s\"\u003eY/\u003c/span\u003e\u003cspan class=\"si\"\u003e%\u003c/span\u003e\u003cspan class=\"s\"\u003em/\u003c/span\u003e\u003cspan class=\"si\"\u003e%\u003c/span\u003e\u003cspan class=\"s\"\u003ed \u003c/span\u003e\u003cspan class=\"si\"\u003e%\u003c/span\u003e\u003cspan class=\"s\"\u003eH:\u003c/span\u003e\u003cspan class=\"si\"\u003e%\u003c/span\u003e\u003cspan class=\"s\"\u003eM:\u003c/span\u003e\u003cspan class=\"si\"\u003e%\u003c/span\u003e\u003cspan class=\"s\"\u003eS\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# 1カラム目に時間を挿入します\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ecsv_list\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etime_\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# アクセスするURL\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"http://www.nikkei.com/markets/kabu/\"\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# URLにアクセスする htmlが帰ってくる → \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;経済、株価、ビジネス、政治のニュース:日経電子版\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body....\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eurllib2\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eurlopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# htmlをBeautifulSoupで扱う\n\u003c/span\u003e    \u003cspan class=\"n\"\u003esoup\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"html.parser\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# span要素全てを摘出する→全てのspan要素が配列に入ってかえされます→[\u0026lt;span class=\"m-wficon triDown\"\u0026gt;\u0026lt;/span\u0026gt;, \u0026lt;span class=\"l-h...\n\u003c/span\u003e    \u003cspan class=\"n\"\u003espan\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esoup\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efind_all\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"span\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# print時のエラーとならないように最初に宣言しておきます。\n\u003c/span\u003e    \u003cspan class=\"n\"\u003enikkei_heikin\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# for分で全てのspan要素の中からClass=\"mkc-stock_prices\"となっている物を探します\n\u003c/span\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003etag\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003espan\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# classの設定がされていない要素は、tag.get(\"class\").pop(0)を行うことのできないでエラーとなるため、tryでエラーを回避する\n\u003c/span\u003e        \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# tagの中からclass=\"n\"のnの文字列を摘出します。複数classが設定されている場合があるので\n\u003c/span\u003e            \u003cspan class=\"c1\"\u003e# get関数では配列で帰ってくる。そのため配列の関数pop(0)により、配列の一番最初を摘出する\n\u003c/span\u003e            \u003cspan class=\"c1\"\u003e# \u0026lt;span class=\"hoge\" class=\"foo\"\u0026gt;  →   [\"hoge\",\"foo\"]  →   hoge\n\u003c/span\u003e            \u003cspan class=\"n\"\u003estring_\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etag\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n            \u003cspan class=\"c1\"\u003e# 摘出したclassの文字列にmkc-stock_pricesと設定されているかを調べます\n\u003c/span\u003e            \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003estring_\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"s\"\u003e\"mkc-stock_prices\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n                \u003cspan class=\"c1\"\u003e# mkc-stock_pricesが設定されているのでtagで囲まれた文字列を.stringであぶり出します\n\u003c/span\u003e                \u003cspan class=\"n\"\u003enikkei_heikin\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etag\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\n                \u003cspan class=\"c1\"\u003e# 摘出が完了したのでfor分を抜けます\n\u003c/span\u003e                \u003cspan class=\"k\"\u003ebreak\u003c/span\u003e\n        \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# パス→何も処理を行わない\n\u003c/span\u003e            \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# 摘出した日経平均株価を時間とともに出力します。\n\u003c/span\u003e    \u003cspan class=\"k\"\u003eprint\u003c/span\u003e \u003cspan class=\"n\"\u003etime_\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enikkei_heikin\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# 2カラム目に日経平均を記録します\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ecsv_list\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enikkei_heikin\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# csvに追記敷きます\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ewriter\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewriterow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_list\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# ファイル破損防止のために閉じます\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eclose\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003e流れ的には言えば\u003cbr\u003e\n1.n時00秒になるまで待機\u003cbr\u003e\n2.csvをオープン\u003cbr\u003e\n3.レコードを作成\u003cbr\u003e\n4.日経平均株価を取得\u003cbr\u003e\n5.レコードに追加\u003cbr\u003e\n6.レコードをcsvに書き込み\u003c/p\u003e\n\n\u003cp\u003eってなわけです\u003c/p\u003e\n\n\u003cp\u003eこれを実行し続けると一時間に一回アクセスを行い日経平均を取得し、記録してくれます。\u003c/p\u003e\n\n\u003cp\u003eこれを応用すればなんだってできます\u003c/p\u003e\n\n\u003cp\u003eたとえば、某南米の長い川でのセール時でのカート高速追加（俗に言うスクリプト勢）なんてできたり。。。\u003c/p\u003e\n\n\u003cp\u003eあまりお勧めはしませんが\u003c/p\u003e\n\n\u003cp\u003eでは！\u003c/p\u003e\n\n\u003ch4\u003e\n\u003cspan id=\"こちらもどうぞ\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%93%E3%81%A1%E3%82%89%E3%82%82%E3%81%A9%E3%81%86%E3%81%9E\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eこちらもどうぞ\u003c/h4\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita.com/Azunyan1111/items/b161b998790b1db2ff7a\"\u003ePython Webスクレイピング テクニック集「取得できない値は無い」JavaScript対応\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://qiita.com/Azunyan1111/items/a1b6c58dc868814efb51\" id=\"reference-21867ef0d32eeceb5922\"\u003e【毎秒1万リクエスト!?】Go言語で始める爆速Webスクレイピング【Golang】\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://qiita.com/Azunyan1111/items/975c67129d99de33dc21\" id=\"reference-4b273e5ea4c5a09074c6\"\u003e【初心者向け】Re:ゼロから始める遺伝的アルゴリズム【人工知能】\u003c/a\u003e\u003c/p\u003e\n","createdAt":"2016-12-01T15:04:15Z","elapsedYearsFromUpdatedAt":1,"isDeprecated":true,"isDestroyableByViewer":false,"isEditRequestSendableByViewer":true,"isLikableByViewer":true,"isLikedByViewer":false,"isPublic":true,"isSlide":false,"isStockableByViewer":true,"isStockedByViewer":false,"isUpdatableByViewer":false,"isUpdated":true,"likesCount":1150,"originalId":443131,"title":"Python Webスクレイピング 実践入門","toc":"\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%84%E3%82%8B%E3%81%93%E3%81%A8\"\u003eやること\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%B3%A8%E6%84%8F\"\u003e注意\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E4%BD%95%E3%82%92%E4%BD%BF%E3%81%86%E3%81%AE\"\u003e何を使うの？\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\"\u003eライブラリインストール\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%89%8B%E5%A7%8B%E3%82%81%E3%81%AB%E6%97%A5%E6%9C%AC%E7%B5%8C%E6%B8%88%E6%96%B0%E8%81%9E%E3%81%AE%E3%83%9A%E3%83%BC%E3%82%B8%E3%82%BF%E3%82%A4%E3%83%88%E3%83%AB%E3%82%92%E5%8F%96%E5%BE%97%E3%81%97%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86\"\u003e手始めに日本経済新聞のページタイトルを取得してみよう！\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E8%B7%B5\"\u003e実践！\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%97%A5%E7%B5%8C%E5%B9%B3%E5%9D%87%E6%A0%AA%E4%BE%A1%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%B8%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9\"\u003e日経平均株価ページへアクセス\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%97%A5%E7%B5%8C%E5%B9%B3%E5%9D%87%E6%A0%AA%E4%BE%A1%E5%8F%96%E5%BE%97\"\u003e日経平均株価取得\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%B9%B0%E3%82%8A%E8%BF%94%E3%81%97%E3%81%A8csv%E5%87%BA%E5%8A%9B\"\u003e繰り返しとcsv出力\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%93%E3%81%A1%E3%82%89%E3%82%82%E3%81%A9%E3%81%86%E3%81%9E\"\u003eこちらもどうぞ\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","totalPv":262035,"updatedAt":"2018-02-23T09:56:13Z","uuid":"9b3d16428d2bcc7c9406","adventCalendarItem":{"day":2,"calendar":{"name":"クローラー／Webスクレイピング","urlName":"crawler","year":2016,"organization":null}},"author":{"description":"#seccamp 18 18Y 16F/Golang/Webセキュリティ/サイバー犯罪/Tor研究＆Torサービス運営/ゲーム会社","name":"","profileImageUrl":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2Fprofile-images%2F1535776100?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=ab8b67ebe7389304d51aed7504627ea6","profileImageUrlW48":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2Fprofile-images%2F1535776100?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=ab8b67ebe7389304d51aed7504627ea6","profileImageUrlW75":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F110135%2Fprofile-images%2F1535776100?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=c22b90166a09de5356165601b447702d","urlName":"Azunyan1111","isFollowedByViewer":false,"isFollowableByViewer":true,"websiteUrl":"https://blog.azunyan1111.com/","organizations":{"edges":[{"node":{"name":"合同会社ナクサ","logoUrl":"https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/89af7512122455dd63dad532b508af9a99523593/original.jpg?1571198423","urlName":"naxa","description":"弊社では、ウェブアプリケーションのサーバサイド、アプリ、インフラにおける受託開発やコンサルティングをお受けしています。","url":"https://www.naxa.co.jp"}}]}},"tags":[{"name":"Python","urlName":"python"},{"name":"スクレイピング","urlName":"%e3%82%b9%e3%82%af%e3%83%ac%e3%82%a4%e3%83%94%e3%83%b3%e3%82%b0"}],"followingLikers":{"edges":[]},"comments":{"totalCount":6}},"viewer":null,"analyticsTrackingId":null}</script>
      
<footer id="globalFooter" class="st-Footer"><div class="st-Footer_container"><div class="st-Footer_start"><div class="st-Footer_logo"><svg viewbox="0 0 426.57 130" xmlns="http://www.w3.org/2000/svg"><circle cx="167.08" cy="21.4" r="12.28" /><path d="M250.81 29.66h23.48v18.9h-23.48z" /><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z" /><circle cx="216.33" cy="21.4" r="12.28" /></svg></div><div class="st-Footer_catchcopy">How developers code is here.</div><div class="st-Footer_socials"><a class="fa fa-twitter" href="https://twitter.com/qiita"></a><a class="fa fa-facebook-square" href="https://www.facebook.com/qiita/"></a></div></div><div class="st-Footer_end"><div class="st-Footer_qiita"><div class="st-Footer_label">Qiita</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="/about">About</a><a href="/terms">利用規約</a><a href="/privacy">プライバシー</a><a target="_blank" href="http://help.qiita.com/ja/articles/qiita-community-guideline">ガイドライン</a></div><div class="st-Footer_column"><a href="/api/v2/docs">API</a><a href="/feedback/new">ご意見</a><a href="https://help.qiita.com">ヘルプ</a><a target="_blank" href="https://qiita.com/ads?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">広告掲載</a></div></div></div><div class="st-Footer_increments"><div class="st-Footer_label">Increments</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="https://increments.co.jp/company/">About</a><a href="https://increments.co.jp/jobs/">採用情報</a><a href="https://blog.qiita.com">ブログ</a></div><div class="st-Footer_column"><a href="https://teams.qiita.com/">Qiita Team</a><a href="https://jobs.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Jobs</a><a href="https://zine.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Zine</a></div></div></div></div></div><div class="st-Footer_copyright">© 2011-2019 Increments Inc.</div></footer><div class="p-messages"><div id="Snackbar-react-component-9fd2fa99-e7db-4dbc-9aae-ecafa8b979f2"><div class="msg-Container"><div class="msg-Item msg-Item- msg-Item-dismissible" style="visibility:hidden;opacity:0;transition:visibility 0ms 50ms, opacity 50ms linear"><div class="msg-Item_body"></div><button class="msg-Item_dismiss"><span class="fa fa-close"></span></button></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="Snackbar" data-dom-id="Snackbar-react-component-9fd2fa99-e7db-4dbc-9aae-ecafa8b979f2">{}</script>
      
</div><div id="LoginModal-react-component-fe45c1fc-6dd1-4537-b9b4-954b83aa8b71"><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body lm-Dialog"><div class="fa fa-times lm-Dialog_close"></div><div class="lm-Dialog_title">ユーザー登録して、Qiitaをもっと便利に使ってみませんか。</div><div class="lm-Dialog_message-pc">この機能を利用するにはログインする必要があります。ログインするとさらに便利にQiitaを利用できます。</div><div class="lm-Dialog_message-mobile">この機能を利用するにはログインする必要があります。ログインするとさらに便利にQiitaを利用できます。</div><ol class="lm-Dialog_list"><li>あなたにマッチした記事をお届けします<div class="description">ユーザーやタグをフォローすることで、あなたが興味を持つ技術分野の情報をまとめてキャッチアップできます</div></li><li>便利な情報をあとで効率的に読み返せます<div class="description">気に入った記事を「ストック」することで、あとからすぐに検索できます</div></li></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2FAzunyan1111%2Fitems%2F9b3d16428d2bcc7c9406&amp;realm=qiita" class="lm-Dialog_button lm-Dialog_button-signup">登録する</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2FAzunyan1111%2Fitems%2F9b3d16428d2bcc7c9406&amp;realm=qiita" class="lm-Dialog_button lm-Dialog_button-signin">ログインする</a></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="LoginModal" data-dom-id="LoginModal-react-component-fe45c1fc-6dd1-4537-b9b4-954b83aa8b71">{}</script>
      
</div><div id="dataContainer" style="display: none;" data-config="{&quot;actionPath&quot;:&quot;public/items#show&quot;,&quot;settings&quot;:{&quot;analyticsTrackingId&quot;:&quot;UA-24675221-12&quot;,&quot;mixpanelToken&quot;:&quot;17d24b448ca579c365d2d1057f3a1791&quot;,&quot;assetsMap&quot;:{},&quot;csrfToken&quot;:&quot;CbHzmgXkr8ZtA4Ik4fEY+zo4BFs1wFY64NI9DCJNzAcoGMxCAXfR+/UWMrQMJlMU6ntdIj0OtBeCCGazA7PwLA==&quot;,&quot;locale&quot;:&quot;ja&quot;},&quot;currentUser&quot;:null}" /></body></html><script type="application/json" data-js-react-on-rails-store="AppStore">{"snackbar":{"type":"","body":"","isActive":false}}</script>