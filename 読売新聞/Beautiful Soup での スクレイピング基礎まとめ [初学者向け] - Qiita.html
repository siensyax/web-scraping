<!DOCTYPE html><html><head><meta charset="utf-8" /><title>Beautiful Soup での スクレイピング基礎まとめ [初学者向け] - Qiita</title><meta content="width=device-width,initial-scale=1,shrink-to-fit=no" name="viewport" /><meta content="#55c500" name="theme-color" /><meta content="XWpkTG32-_C4joZoJ_UsmDUi-zaH-hcrjF6ZC_FoFbk" name="google-site-verification" /><link href="/manifest.json" rel="manifest" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="oXRiIy75gNKfZ24/neK4kHjfGQJVCE848PI5Y2XS31mA3V37Kmr+7wdy3q9wNfN/qJxAe13GrRWSKGLcRCzjcg==" /><link rel="shortcut icon" type="image/x-icon" href="https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico" /><link rel="apple-touch-icon" type="image/png" href="https://cdn.qiita.com/assets/favicons/public/apple-touch-icon-ec5ba42a24ae923f16825592efdc356f.png" /><link rel="stylesheet" media="all" href="https://cdn.qiita.com/assets/public/style-2dbf48653eb2716a17796ccbca9ef66e.min.css" /><script src="https://cdn.qiita.com/assets/public/v3-bundle-ee60236b19f53e1a678e06d90fe3e29b.min.js" defer="defer"></script><meta content="summary" name="twitter:card" /><meta content="@Qiita" name="twitter:site" /><meta content="@oregaU_MAda" name="twitter:creator" /><meta property="og:type" content="article"><meta property="og:title" content="Beautiful Soup での スクレイピング基礎まとめ [初学者向け] - Qiita"><meta property="og:image" content="https://cdn.qiita.com/assets/qiita-fb-fe28c64039d925349e620ba55091e078.png"><meta property="og:description" content="#概要
pythonを使って何かやりたいと思っている今日このごろ、、、
~~エロい~~健全な画像を自動収集したいなーと思って今流行りのスクレイピングをやってみました。
Beautiful Soupについて調べたので、基礎的なことをまと..."><meta content="https://qiita.com/U-MA/items/896c49d46585e32ff7b1" property="og:url" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><meta content="スクレイピング,初心者,Python3,備忘録,BeautifulSoup" name="keywords" /><script>window.frtn=window.frtn||function(){ (frtn.q=frtn.q||[]).push(arguments) };
frtn("init",{
service_id:"cova_248",
site_id:"site_134",
tag_id:"tag_283"
});
frtn("send","pageview");</script><script defer="" src="https://frtn.socdm.com/tags/insight.js" type="text/javascript"></script><script>!function(t,e){if(void 0===e[t]){e[t]=function(){e[t].clients.push(this),this._init=[Array.prototype.slice.call(arguments)]},e[t].clients=[];for(var r=function(t){return function(){return this["_"+t]=this["_"+t]||[],this["_"+t].push(Array.prototype.slice.call(arguments)),this}},s=["blockEvents","unblockEvents","setSignedMode","setAnonymousMode","resetUUID","addRecord","fetchGlobalID","set","trackEvent","trackPageview","trackClicks","ready"],n=0;n<s.length;n++){var c=s[n];e[t].prototype[c]=r(c)}var o=document.createElement("script");o.type="text/javascript",o.async=!0,o.src=("https:"===document.location.protocol?"https:":"http:")+"//cdn.treasuredata.com/sdk/2.1/td.min.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(o,a)}}("Treasure",this);

// Configure an instance for your database
var td = new Treasure({
  host: 'in.treasuredata.com',
  writeKey: '10614/f5a4453704ad12facc47fe5281fd57526a6119e9',
  database: 'qiita_public',
  startInSignedMode: true
});

// Enable cross-domain tracking
td.set('$global', 'td_global_id', 'td_global_id');
// Track pageview information to 'pageviews' table
td.set('pageviews_all', {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"U-MA","type":"items","id":"896c49d46585e32ff7b1"}})
td.trackPageview('pageviews_all');</script><script>td.set('pageviews_anonymous_user', {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"U-MA","type":"items","id":"896c49d46585e32ff7b1"}})
td.trackPageview('pageviews_anonymous_user');</script></head><body><div class="allWrapper"><div class="st-HeaderContainer"><div id="GlobalHeader-react-component-80b4bfb8-674b-40eb-9cb1-a68d2b8f8ed3"><div class="st-Header"><div class="st-Header_container"><div class="st-Header_start"><a href="/" class="st-Header_logo mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 426.57 130"><circle cx="167.08" cy="21.4" r="12.28"></circle><path d="M250.81 29.66h23.48v18.9h-23.48z"></path><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z"></path><circle cx="216.33" cy="21.4" r="12.28"></circle></svg></a><div><div class="st-Header_realmSelector" tabindex="0"><span class="fa fa-fw fa-caret-down"></span></div><div class="st-Header_dropdown st-RealmSelector"><div class="st-RealmSelector_realms"><a class="st-Header_dropdownItem st-RealmItem" href="https://qiita.com/"><div class="st-RealmItem_statusIcon"><span class="fa fa-fw fa-check"></span></div><div class="st-RealmItem_humanName">Qiita</div></a></div><hr/><div class="st-RealmSelector_supplements"><div class="st-RealmSelector_label">ログイン中のチームがありません</div><a href="https://teams-center.qiita.com/find_team" class="st-Header_dropdownItem st-RealmSelectorSupplement"><div class="st-RealmSelectorSupplement_icon"><span class="fa fa-fw fa-sign-in"></span></div><div>Qiita Team にログイン...</div></a></div></div></div><div><div class="st-Header_community" tabindex="0">コミュニティ<span class="fa fa-fw fa-caret-down ml-1of2"></span></div><div class="st-Header_dropdown"><a href="/users" class="st-Header_dropdownItem"><span class="fa fa-fw fa-users mr-1of2"></span>ユーザー一覧</a><a href="/organizations" class="st-Header_dropdownItem"><span class="fa fa-fw fa-building-o mr-1of2"></span>Organization一覧</a><a href="/advent-calendar" class="st-Header_dropdownItem"><span class="fa fa-fw fa-calendar mr-1of2"></span>アドベントカレンダー</a><div class="st-Header_dropdownSeparator"></div><a href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-search mr-1of2"></span>Qiita Jobs</a><a href="https://qiitadon.com/" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-comments-o mr-1of2"></span>Qiitadon (β)</a><a href="https://zine.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-newspaper-o mr-1of2"></span>Qiita:Zine</a><div class="st-Header_dropdownSeparator"></div><a href="https://help.qiita.com/ja/articles/qiita-community-guideline" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-book mr-1of2"></span>コミュニティガイドライン</a><a href="https://help.qiita.com/ja/articles/qiita-article-guideline" class="st-Header_dropdownItem" target="_blank"><span class="fa fa-fw fa-book mr-1of2"></span>良い記事を書くために</a></div></div><form class="st-Header_search" action="/search" method="get"><span class="fa fa-search"></span><input type="search" class="st-Header_searchInput" autoComplete="off" placeholder="キーワードを入力" value="" name="q" required=""/></form><div class="st-Header_searchButton"><span class="fa fa-search"></span></div></div><div class="st-Header_end"><a class="st-Header_signupButton" href="/signup?redirect_to=%2FU-MA%2Fitems%2F896c49d46585e32ff7b1">ユーザ登録</a><a class="st-Header_loginLink" href="/login?redirect_to=%2FU-MA%2Fitems%2F896c49d46585e32ff7b1">ログイン</a></div><div class="st-Header_overlay"></div><form class="st-Header_searchModal" action="/search" method="get"><input type="text" class="st-Header_searchModalInput" autoComplete="off" placeholder="キーワードを入力" value="" name="q" required=""/></form></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="GlobalHeader" data-dom-id="GlobalHeader-react-component-80b4bfb8-674b-40eb-9cb1-a68d2b8f8ed3">{"unreadNotificationsCount":null,"realms":[{"humanName":"Qiita","isCurrentRealm":true,"isQiita":true,"isQiitaTeam":false,"loggedInUser":null,"teamId":null,"url":"https://qiita.com/"}],"teamFindUrl":"https://teams-center.qiita.com/find_team","isTeamOnlyUser":null,"currentUser":null}</script>
      
</div><div class="st-HeaderAlert st-HeaderAlert-warning"><div class="st-HeaderAlert_body"></div></div><div class="ac-CampaignLink"><div class="ac-CampaignLink_container"><a href="/advent-calendar/2019">Qiita Advent Calendar 2019 開催中！ 最高に盛り上がる年末にしていきましょう :)</a><a href="/advent-calendar/2019">&gt; カレンダーを見る</a></div></div><script type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"/","name":"Qiita"}},{"@type":"ListItem","position":2,"item":{"@id":"/tags/%23%3CQiita::Graph::Result:0x0000555af93306e0%3E","name":"スクレイピング"}}]}</script><script>td.trackEvent('pageviews_article',{
    user_id: "",
    article_id: "648045",
    article_uuid: "896c49d46585e32ff7b1",
    td_description: "&quot;#概要\npythonを使って何かやりたいと思っている今日このごろ、、、\n~~エロい~~健全な画像を自動収集したいなーと思って今流行りのスクレイピングをやってみました。\nBeautiful Soupについて調べたので、基礎的なことをまとめておきます。\n作成者が初学者のため、完全初学者向けです。\n\n#スクレイピングとは?\nまずはスクレイピングとは何かの確認。\nwikipedia先生より。\n\u0026amp;gt;ウェブスクレイピング（英: Web scraping）とは、ウェブサイトから情報を抽出するコンピュータソフトウェア技術のこと。\n~中略~\nウェブスクレイピングではウェブ上の非構造化データの変換、一般的にはHTMLフォーマットからデータベースやスプレッドシートに格納・分析可能な構造化データへの変換に、より焦点が当てられている。\n\n構造化データ/非構造化データとは、簡単にまとめると\n\n- 構造化データ\n    - CSVファイル, Excelファイル 等\n    - 「行」, 「列」 によって、データが明確に分類できる。\n- 非構造化データ\n    - htmlファイル, Jsonファイル, テキストデータ 等\n    - 「行」, 「列」 だけでは分類ができない。\n\n「行」, 「列」でデータを管理したほうが、コンピュータ的に都合がいい。\nつまるところ、スクレイピングとは\n\u0026amp;lt;b\u0026amp;gt;「非構造化データから情報を抽出して、コンピュータがより扱い易い構造化データに格納する」\u0026amp;lt;/b\u0026amp;gt;\nことが目的ともいえる。\n\nちなみに、webサイトからデータを取得する「クローリング」というものもある。\nクローリングは情報の抽出ではなく、任意のデータを取得することを指す。\n「スクレイピング」は、htmlファイル全体を取得しその中から目的のデータを抽出すること。\n「クローリング」は、htmlファイル全体, あるいは目的のデータをそのまま取得すること。\n\u0026amp;lt;b\u0026amp;gt;「*クローリング*」したhtmlファイルを「*スクレイピング*」する\u0026amp;lt;/b\u0026amp;gt;\nと考えるとわかりやすい。\n\n\n\n#Beautiful Soupとは?\n\u0026amp;lt;b\u0026amp;gt;Pythonのライブラリの一つで、スクレイピングに特化したモジュール\u0026amp;lt;/b\u0026amp;gt;。\nhtmlファイルをタグ情報から解析し、抽出データを格納したインスタンスを返す。\nhtmlの構造とpythonの基礎が分かっていれば、非常に使いやすい。\n\n#やってみよう\n##環境\n- Mac OS High Sierra ver 10.13.4\n- Python 3.6.5 (anaconda)\n\n##環境構築\n###仮想環境の作成\nスクレイピング用の仮想環境を作成する。\n\n```\nmkdir [dir_name]\ncd [dir_name]\npython -m venv [env_name]\nsource [env_name]/bin/activate\n```\n\n仮想環境を構築完了。\n\n###仮想環境にBeautiful Soupをインストール\n\n```py\n\npip install beautifulsoup4\npip list\n```\nbeautifulsoup4 が表示されていたら成功。\n\n##Beautiful Soupを動かしてみる\nhtmlファイルの取得には、pythonの標準搭載モジュールである\u0026amp;lt;b\u0026amp;gt;urllib\u0026amp;lt;/b\u0026amp;gt;を使用。\n読売新聞のヘッドラインを取得するコードを書いた。\n[読売新聞](http://www.yomiuri.co.jp/)のページソースを確認しながらだと、以下の記事が理解しやすい。\n\u0026amp;quot;list-main-news\u0026amp;quot;クラス内の\u0026amp;quot;headline\u0026amp;quot;クラスのテキストを取得する。\n\n\n###コード\n\n```py\n\n#coding: UTF-8\nfrom urllib import request\nfrom bs4 import BeautifulSoup\n\ndef scraping():\n    #url\n    url = \u0026amp;quot;http://www.yomiuri.co.jp/\u0026amp;quot;\n\n    #get html\n    html = request.urlopen(url)\n\n    #set BueatifulSoup\n    soup = BeautifulSoup(html, \u0026amp;quot;html.parser\u0026amp;quot;)\n\n    #get headlines\n    mainNewsIndex = soup.find(\u0026amp;quot;ul\u0026amp;quot;, attrs={\u0026amp;quot;class\u0026amp;quot;, \u0026amp;quot;list-main-news\u0026amp;quot;})\n    headlines = mainNewsIndex.find_all(\u0026amp;quot;span\u0026amp;quot;, attrs={\u0026amp;quot;class\u0026amp;quot;, \u0026amp;quot;headline\u0026amp;quot;})\n\n    #print headlines\n    for headline in headlines:\n        print(headline.contents[0], headline.span.string)\n     \nif __name__ == \u0026amp;quot;__main__\u0026amp;quot;:\n    scraping()\n\n```\n\n###実行結果(2018/5/21)\n```\n省庁データ、近く西暦で統一…来春は間に合わず （07:16）\n内閣支持、３ポイント増の４２％…読売世論調査 （06:00）\n政党支持、自民３７％・立民７％…読売世論調査 （22:33）\n働き方法案「今国会で」２５％…読売世論調査 （23:10）\n米朝会談で核解決「期待」６６％…読売世論調査 （06:00）\nヒデキにこの勝利捧げる…交流のＪ１川崎が追悼 （07:29）\n日大監督「かんさい学院」連呼、謝る大学名誤る （12:46）\n駅を１９００ｍ通過、時速６０キロで後進し戻る （19:22）\nスマホで徘徊者捜索実験、ＧＰＳ内蔵靴「有用」 （07:38）\n```\n\n#解説\n##html parser\nhtml parserとは、htmlのタグ情報から情報を解釈するプログラムのこと。\n\u0026amp;gt;パースとは、プログラムのソースコードやXML文書など、一定の文法に従って記述された複雑な構造のテキスト文書を解析し、プログラムで扱えるようなデータ構造の集合体に変換することである。\nパースを行うためのプログラムの総称を「パーサ/パーザ」という。\n\n([Proto Solution](http://www.protosolution.co.jp/glossary/web/ha/pa-su.html)より)\n\nhtml parserは、html.parser以外にも多数存在する。\n本記事では標準搭載の「html.parser」を使用。\n\n```py\n\nsoup = BeautifulSoup(html, \u0026amp;quot;html.parser\u0026amp;quot;)\n```\nBeautifulSoupにhtmlファイルとhtml parserを渡し、インスタンス作成。\n\n##Beautiful Soupの操作\n- find()\n    - 一番最初に合致した結果のみを返す\n- find_all()\n    - 合致した結果を全てリストで返す\n\nこの2つのメソッドが主に使用される。\n引数でフィルタをかけることにより、任意のhtmlタグ内の情報を保持した\n\u0026amp;lt;b\u0026amp;gt;bs4.element.Tag\u0026amp;lt;/b\u0026amp;gt;型のインスタンスを取得できる。\n\n\n```py\n\nmainNewsIndex = soup.find(\u0026amp;quot;ul\u0026amp;quot;, attrs={\u0026amp;quot;class\u0026amp;quot;, \u0026amp;quot;list-main-news\u0026amp;quot;})\nheadlines = mainNewsIndex.find_all(\u0026amp;quot;span\u0026amp;quot;, attrs={\u0026amp;quot;class\u0026amp;quot;, \u0026amp;quot;headline\u0026amp;quot;})\n```\n\nまず、[読売新聞](http://www.yomiuri.co.jp/)のページには\u0026amp;quot;list-main-news\u0026amp;quot;クラスが一つしか存在しない。\nそのため、find()を使用する。(find_all()だと、htmlファイル全体を探索してしまう。)\nhtmlファイル全体から\\\u0026amp;lt;ul\\\u0026amp;gt;タグの \u0026amp;quot;list-main-news\u0026amp;quot; クラスを抽出し、\nmainNewsIndexにインスタンスを格納。\nmainNewsIndexから、さらに\u0026amp;quot;headline\u0026amp;quot;クラスを抽出。\n取得したい\\\u0026amp;lt;span\\\u0026amp;gt;タグの\u0026amp;quot;headline\u0026amp;quot;クラスは複数存在するので、find_all()でまとめて抽出。\nこれで最終的には、\u0026amp;quot;bs4.element.Tag\u0026amp;quot;型のインスタンスのリストがheadlinesに格納される。\n\n- find()\n- find_all()\n\n以上2つのメソッドは、フィルターをかけて要素を取得する。\nフィルターのかけ方については、わかりやすくまとめてくださっています。\n[PythonとBeautiful Soupでスクレイピング](https://qiita.com/itkr/items/513318a9b5b92bd56185)\n[萬九郎の硬い船](http://mankuro.hateblo.jp/entry/2017/05/02/beautifulsoup4-find-and-find_all/)\n\n##bs4.element.Tag　とは\n- find()\n- find_all()\n\nこれらを用いると最終的に返されるインスタンス。\n中身を見てみる。\n\n###コード\n```py\n\nimport pprint\n\n~(中略)~\n\nfor headline in headlines:\n    print(type(headline))\n    pprint.pprint(headline.__dict__)\n```\n\n###実行結果\n```\n\u0026amp;lt;class \u0026amp;#39;bs4.element.Tag\u0026amp;#39;\u0026amp;gt;\n{\u0026amp;#39;attrs\u0026amp;#39;: {\u0026amp;#39;class\u0026amp;#39;: [\u0026amp;#39;headline\u0026amp;#39;]},\n\u0026amp;#39;can_be_empty_element\u0026amp;#39;: False,\n\u0026amp;#39;contents\u0026amp;#39;: [\u0026amp;#39;栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る\u0026amp;#39;, \u0026amp;lt;span class=\u0026amp;quot;update\u0026amp;quot;\u0026amp;gt;（18:05）\u0026amp;lt;/span\u0026amp;gt;],\n\u0026amp;#39;hidden\u0026amp;#39;: False,\n\u0026amp;#39;known_xml\u0026amp;#39;: False,\n\u0026amp;#39;name\u0026amp;#39;: \u0026amp;#39;span\u0026amp;#39;,\n\u0026amp;#39;namespace\u0026amp;#39;: None,\n\u0026amp;#39;next_element\u0026amp;#39;: \u0026amp;#39;栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る\u0026amp;#39;,\n\u0026amp;#39;next_sibling\u0026amp;#39;: \u0026amp;#39;\\n\u0026amp;#39;,\n\u0026amp;#39;parent\u0026amp;#39;: \u0026amp;lt;a href=\u0026amp;quot;http://www.yomiuri.co.jp/sports/sumo/20180521-OYT1T50054.html?from=ytop_main9\u0026amp;quot;\u0026amp;gt;\n         \u0026amp;lt;span class=\u0026amp;quot;headline\u0026amp;quot;\u0026amp;gt;栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る\u0026amp;lt;span class=\u0026amp;quot;update\u0026amp;quot;\u0026amp;gt;（18:05）\u0026amp;lt;/span\u0026amp;gt;\u0026amp;lt;/span\u0026amp;gt;\n         \u0026amp;lt;span class=\u0026amp;quot;icon-photo\u0026amp;quot;\u0026amp;gt;\u0026amp;lt;/span\u0026amp;gt;\n         \u0026amp;lt;/a\u0026amp;gt;,\n\u0026amp;#39;parser_class\u0026amp;#39;: \u0026amp;lt;class \u0026amp;#39;bs4.BeautifulSoup\u0026amp;#39;\u0026amp;gt;,\n\u0026amp;#39;prefix\u0026amp;#39;: None,\n\u0026amp;#39;preserve_whitespace_tags\u0026amp;#39;: {\u0026amp;#39;textarea\u0026amp;#39;, \u0026amp;#39;pre\u0026amp;#39;},\n\u0026amp;#39;previous_element\u0026amp;#39;: \u0026amp;#39;\\n\u0026amp;#39;,\n\u0026amp;#39;previous_sibling\u0026amp;#39;: \u0026amp;#39;\\n\u0026amp;#39;}\n```\n\nこのように様々な情報が辞書型で格納されている。\nもちろん、「.key」でつなぐことでこれらのvalueを取得できる。\n\n```py\n\n#タグ直下のテキストを取得する\nheadline.contents[0]\n#時刻を取得する\nheadline.span.contents[0]\n```\n- .string\n- .text (指定場所以下のテキストを全て取得)\n\nとしてもテキスト内容は取得できる。\nしかし、タグが多重構造の場合、外側のみのテキスト内容取得ができなかったので\n.contents[] で指定して取得するのがよさそう。\n\n#まとめ\n\n\nスクレイピングの基礎とBeautiful Soup4についてまとめました。\n次回は一定時間毎にこれらを動作させるプログラムを書いてみたいと思いますー\n&quot;",
    td_title: "&quot;Beautiful Soup での スクレイピング基礎まとめ [初学者向け]&quot;"
  })</script><script async="" src="https://cdn.bigmining.com/private/js/qiita_bigmining.js"></script><div style="display:none"><div class="TagList__label"><span></span><span>スクレイピング</span></div><div class="TagList__label"><span></span><span>初心者</span></div><div class="TagList__label"><span></span><span>Python3</span></div><div class="TagList__label"><span></span><span>備忘録</span></div><div class="TagList__label"><span></span><span>BeautifulSoup</span></div></div><img style="display:block;margin:0;padding:0;border:0;outline:0;width:0;height:0;line-height:0;" alt="" src="https://relay-dsp.ad-m.asia/dmp/sync/bizmatrix?pid=c3ed207b574cf11376&amp;d=x18o8hduaj&amp;uid=" /><script type="application/json" id="js-react-on-rails-context">{"railsEnv":"production","inMailer":false,"i18nLocale":"ja","i18nDefaultLocale":"en","href":"https://qiita.com/U-MA/items/896c49d46585e32ff7b1","location":"/U-MA/items/896c49d46585e32ff7b1","scheme":"https","host":"qiita.com","port":null,"pathname":"/U-MA/items/896c49d46585e32ff7b1","search":null,"httpAcceptLanguage":"ja,en-US;q=0.9,en;q=0.8","actionPath":"public/items#show","settings":{"analyticsTrackingId":"UA-24675221-12","mixpanelToken":"17d24b448ca579c365d2d1057f3a1791","assetsMap":{},"csrfToken":"3qZjqhzfLD/XefTo2SjSbHjsv2EUR2K5XYePvOtaqTf/D1xyGExSAk9sRHg0/5mDqK/mGByJgJQ/XdQDyqSVHA==","locale":"ja"},"currentUser":null,"isLoggedIn":false,"serverSide":false}</script>
<div id="PersonalPublicArticle-react-component-e1891f0f-ea8a-42d5-a22d-d44774ac946c"><div class="p-items" itemscope="" itemType="http://schema.org/Article"><div class="p-items_wrapper"><div class="p-items_container"><div class="p-items_main"><div class="p-items_article"><div class="it-Header"><div class="u-flex-center-between mb-3"><div class="it-Header_info"><div class="it-Header_author"><a href="/U-MA"><img src="https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F252009%2Fprofile-images%2F1526810038?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;lossless=0&amp;w=48&amp;s=787411360b8d778d1ba58c3830830070" alt="U-MA" class="it-Header_authorImage"/></a><a href="/U-MA" class="it-Header_authorName">@<!-- -->U-MA</a></div><div class="it-Header_time"><span><meta content="2018-05-21T11:59:01Z" itemProp="datePublished"/><time dateTime="2018-05-22T22:54:00Z" itemProp="dateModified">2018年05月22日に更新</time></span></div><div class="it-Header_meta"><div class="it-Header_manipulate"><div class="it-Header_dropdown"><span class="it-Header_dropdownToggle" tabindex="0"><span class="fa fa-ellipsis-h fa-lg"></span></span><div class="st-Dropdown right"><div><div class="it-Header_dropdown-title">記事の改善</div><a class="st-Dropdown_item" href="/drafts/896c49d46585e32ff7b1/edit"><span class="fa fa-fw fa-code-fork pr-1"></span>編集リクエストを送る</a><div class="st-Dropdown_separator"></div></div><div class="it-Header_dropdown-title">記事の情報</div><a class="st-Dropdown_item" href="/U-MA/items/896c49d46585e32ff7b1/revisions"><span class="fa fa-fw fa-history pr-1"></span>編集履歴</a><a class="st-Dropdown_item" href="/U-MA/items/896c49d46585e32ff7b1/patches"><span class="fa fa-fw fa-inbox pr-1"></span>編集リクエスト一覧</a><a class="st-Dropdown_item" href="/U-MA/items/896c49d46585e32ff7b1/likers"><span class="fa fa-fw fa-thumbs-up pr-1"></span>いいねしたユーザ一覧</a><a class="st-Dropdown_item" href="/U-MA/items/896c49d46585e32ff7b1.md"><span class="fa fa-fw fa-file-text-o pr-1"></span>Markdown で本文を見る</a><div class="st-Dropdown_separator"></div><div class="st-Dropdown_item"><span class="fa fa-fw fa-flag pr-1"></span>問題がある記事を報告する</div></div></div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">この記事にどのような問題がありますか？</span></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>スパムです</label></div><div class="st-Form"><label><input type="radio" name="reason" value="harassment" required=""/>攻撃的または迷惑な内容を含んでいます</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>不適切な内容を含んでいます</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="送信"/></div></form></div></div></div></div></div><h1 class="it-Header_title" itemProp="headline">Beautiful Soup での スクレイピング基礎まとめ [初学者向け]</h1><div class="it-Tags"><a href="/tags/%e3%82%b9%e3%82%af%e3%83%ac%e3%82%a4%e3%83%94%e3%83%b3%e3%82%b0" class="it-Tags_item"><span>スクレイピング</span></a><a href="/tags/%e5%88%9d%e5%bf%83%e8%80%85" class="it-Tags_item"><span>初心者</span></a><a href="/tags/python3" class="it-Tags_item"><span>Python3</span></a><a href="/tags/%e5%82%99%e5%bf%98%e9%8c%b2" class="it-Tags_item"><span>備忘録</span></a><a href="/tags/beautifulsoup" class="it-Tags_item"><span>BeautifulSoup</span></a></div></div><div class="it-DeprecationAlert_one mb-5 p-2"><span class="fa fa-warning mr-1"></span>この記事は最終更新日から1年以上が経過しています。</div><section class="it-MdContent" itemProp="articleBody"><div id="personal-public-article-body"><div>
<h1>
<span id="概要" class="fragment"></span><a href="#%E6%A6%82%E8%A6%81"><i class="fa fa-link"></i></a>概要</h1>

<p>pythonを使って何かやりたいと思っている今日このごろ、、、<br>
<del>エロい</del>健全な画像を自動収集したいなーと思って今流行りのスクレイピングをやってみました。<br>
Beautiful Soupについて調べたので、基礎的なことをまとめておきます。<br>
作成者が初学者のため、完全初学者向けです。</p>

<h1>
<span id="スクレイピングとは" class="fragment"></span><a href="#%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0%E3%81%A8%E3%81%AF"><i class="fa fa-link"></i></a>スクレイピングとは?</h1>

<p>まずはスクレイピングとは何かの確認。<br>
wikipedia先生より。</p>

<blockquote>
<p>ウェブスクレイピング（英: Web scraping）とは、ウェブサイトから情報を抽出するコンピュータソフトウェア技術のこと。<br>
~中略~<br>
ウェブスクレイピングではウェブ上の非構造化データの変換、一般的にはHTMLフォーマットからデータベースやスプレッドシートに格納・分析可能な構造化データへの変換に、より焦点が当てられている。</p>
</blockquote>

<p>構造化データ/非構造化データとは、簡単にまとめると</p>

<ul>
<li>構造化データ

<ul>
<li>CSVファイル, Excelファイル 等</li>
<li>「行」, 「列」 によって、データが明確に分類できる。</li>
</ul>
</li>
<li>非構造化データ

<ul>
<li>htmlファイル, Jsonファイル, テキストデータ 等</li>
<li>「行」, 「列」 だけでは分類ができない。</li>
</ul>
</li>
</ul>

<p>「行」, 「列」でデータを管理したほうが、コンピュータ的に都合がいい。<br>
つまるところ、スクレイピングとは<br>
<b>「非構造化データから情報を抽出して、コンピュータがより扱い易い構造化データに格納する」</b><br>
ことが目的ともいえる。</p>

<p>ちなみに、webサイトからデータを取得する「クローリング」というものもある。<br>
クローリングは情報の抽出ではなく、任意のデータを取得することを指す。<br>
「スクレイピング」は、htmlファイル全体を取得しその中から目的のデータを抽出すること。<br>
「クローリング」は、htmlファイル全体, あるいは目的のデータをそのまま取得すること。<br>
<b>「<em>クローリング</em>」したhtmlファイルを「<em>スクレイピング</em>」する</b><br>
と考えるとわかりやすい。</p>

<h1>
<span id="beautiful-soupとは" class="fragment"></span><a href="#beautiful-soup%E3%81%A8%E3%81%AF"><i class="fa fa-link"></i></a>Beautiful Soupとは?</h1>

<p><b>Pythonのライブラリの一つで、スクレイピングに特化したモジュール</b>。<br>
htmlファイルをタグ情報から解析し、抽出データを格納したインスタンスを返す。<br>
htmlの構造とpythonの基礎が分かっていれば、非常に使いやすい。</p>

<h1>
<span id="やってみよう" class="fragment"></span><a href="#%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86"><i class="fa fa-link"></i></a>やってみよう</h1>

<h2>
<span id="環境" class="fragment"></span><a href="#%E7%92%B0%E5%A2%83"><i class="fa fa-link"></i></a>環境</h2>

<ul>
<li>Mac OS High Sierra ver 10.13.4</li>
<li>Python 3.6.5 (anaconda)</li>
</ul>

<h2>
<span id="環境構築" class="fragment"></span><a href="#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89"><i class="fa fa-link"></i></a>環境構築</h2>

<h3>
<span id="仮想環境の作成" class="fragment"></span><a href="#%E4%BB%AE%E6%83%B3%E7%92%B0%E5%A2%83%E3%81%AE%E4%BD%9C%E6%88%90"><i class="fa fa-link"></i></a>仮想環境の作成</h3>

<p>スクレイピング用の仮想環境を作成する。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>mkdir [dir_name]
cd [dir_name]
python -m venv [env_name]
source [env_name]/bin/activate
</pre></div></div>

<p>仮想環境を構築完了。</p>

<h3>
<span id="仮想環境にbeautiful-soupをインストール" class="fragment"></span><a href="#%E4%BB%AE%E6%83%B3%E7%92%B0%E5%A2%83%E3%81%ABbeautiful-soup%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>仮想環境にBeautiful Soupをインストール</h3>

<div class="code-frame" data-lang="py"><div class="highlight"><pre>
<span class="n">pip</span> <span class="n">install</span> <span class="n">beautifulsoup4</span>
<span class="n">pip</span> <span class="nb">list</span>
</pre></div></div>

<p>beautifulsoup4 が表示されていたら成功。</p>

<h2>
<span id="beautiful-soupを動かしてみる" class="fragment"></span><a href="#beautiful-soup%E3%82%92%E5%8B%95%E3%81%8B%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B"><i class="fa fa-link"></i></a>Beautiful Soupを動かしてみる</h2>

<p>htmlファイルの取得には、pythonの標準搭載モジュールである<b>urllib</b>を使用。<br>
読売新聞のヘッドラインを取得するコードを書いた。<br>
<a href="http://www.yomiuri.co.jp/" rel="nofollow noopener" target="_blank">読売新聞</a>のページソースを確認しながらだと、以下の記事が理解しやすい。<br>
"list-main-news"クラス内の"headline"クラスのテキストを取得する。</p>

<h3>
<span id="コード" class="fragment"></span><a href="#%E3%82%B3%E3%83%BC%E3%83%89"><i class="fa fa-link"></i></a>コード</h3>

<div class="code-frame" data-lang="py"><div class="highlight"><pre>
<span class="c1">#coding: UTF-8
</span><span class="kn">from</span> <span class="nn">urllib</span> <span class="kn">import</span> <span class="n">request</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="k">def</span> <span class="nf">scraping</span><span class="p">():</span>
    <span class="c1">#url
</span>    <span class="n">url</span> <span class="o">=</span> <span class="s">"http://www.yomiuri.co.jp/"</span>

    <span class="c1">#get html
</span>    <span class="n">html</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="c1">#set BueatifulSoup
</span>    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>

    <span class="c1">#get headlines
</span>    <span class="n">mainNewsIndex</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">"ul"</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="p">{</span><span class="s">"class"</span><span class="p">,</span> <span class="s">"list-main-news"</span><span class="p">})</span>
    <span class="n">headlines</span> <span class="o">=</span> <span class="n">mainNewsIndex</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">"span"</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="p">{</span><span class="s">"class"</span><span class="p">,</span> <span class="s">"headline"</span><span class="p">})</span>

    <span class="c1">#print headlines
</span>    <span class="k">for</span> <span class="n">headline</span> <span class="ow">in</span> <span class="n">headlines</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">headline</span><span class="o">.</span><span class="n">contents</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">headline</span><span class="o">.</span><span class="n">span</span><span class="o">.</span><span class="n">string</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">scraping</span><span class="p">()</span>

</pre></div></div>

<h3>
<span id="実行結果2018521" class="fragment"></span><a href="#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C2018521"><i class="fa fa-link"></i></a>実行結果(2018/5/21)</h3>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>省庁データ、近く西暦で統一…来春は間に合わず （07:16）
内閣支持、３ポイント増の４２％…読売世論調査 （06:00）
政党支持、自民３７％・立民７％…読売世論調査 （22:33）
働き方法案「今国会で」２５％…読売世論調査 （23:10）
米朝会談で核解決「期待」６６％…読売世論調査 （06:00）
ヒデキにこの勝利捧げる…交流のＪ１川崎が追悼 （07:29）
日大監督「かんさい学院」連呼、謝る大学名誤る （12:46）
駅を１９００ｍ通過、時速６０キロで後進し戻る （19:22）
スマホで徘徊者捜索実験、ＧＰＳ内蔵靴「有用」 （07:38）
</pre></div></div>

<h1>
<span id="解説" class="fragment"></span><a href="#%E8%A7%A3%E8%AA%AC"><i class="fa fa-link"></i></a>解説</h1>

<h2>
<span id="html-parser" class="fragment"></span><a href="#html-parser"><i class="fa fa-link"></i></a>html parser</h2>

<p>html parserとは、htmlのタグ情報から情報を解釈するプログラムのこと。</p>

<blockquote>
<p>パースとは、プログラムのソースコードやXML文書など、一定の文法に従って記述された複雑な構造のテキスト文書を解析し、プログラムで扱えるようなデータ構造の集合体に変換することである。<br>
パースを行うためのプログラムの総称を「パーサ/パーザ」という。</p>
</blockquote>

<p>(<a href="http://www.protosolution.co.jp/glossary/web/ha/pa-su.html" rel="nofollow noopener" target="_blank">Proto Solution</a>より)</p>

<p>html parserは、html.parser以外にも多数存在する。<br>
本記事では標準搭載の「html.parser」を使用。</p>

<div class="code-frame" data-lang="py"><div class="highlight"><pre>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">"html.parser"</span><span class="p">)</span>
</pre></div></div>

<p>BeautifulSoupにhtmlファイルとhtml parserを渡し、インスタンス作成。</p>

<h2>
<span id="beautiful-soupの操作" class="fragment"></span><a href="#beautiful-soup%E3%81%AE%E6%93%8D%E4%BD%9C"><i class="fa fa-link"></i></a>Beautiful Soupの操作</h2>

<ul>
<li>find()

<ul>
<li>一番最初に合致した結果のみを返す</li>
</ul>
</li>
<li>find_all()

<ul>
<li>合致した結果を全てリストで返す</li>
</ul>
</li>
</ul>

<p>この2つのメソッドが主に使用される。<br>
引数でフィルタをかけることにより、任意のhtmlタグ内の情報を保持した<br>
<b>bs4.element.Tag</b>型のインスタンスを取得できる。</p>

<div class="code-frame" data-lang="py"><div class="highlight"><pre>
<span class="n">mainNewsIndex</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">"ul"</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="p">{</span><span class="s">"class"</span><span class="p">,</span> <span class="s">"list-main-news"</span><span class="p">})</span>
<span class="n">headlines</span> <span class="o">=</span> <span class="n">mainNewsIndex</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">"span"</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="p">{</span><span class="s">"class"</span><span class="p">,</span> <span class="s">"headline"</span><span class="p">})</span>
</pre></div></div>

<p>まず、<a href="http://www.yomiuri.co.jp/" rel="nofollow noopener" target="_blank">読売新聞</a>のページには"list-main-news"クラスが一つしか存在しない。<br>
そのため、find()を使用する。(find_all()だと、htmlファイル全体を探索してしまう。)<br>
htmlファイル全体から&lt;ul&gt;タグの "list-main-news" クラスを抽出し、<br>
mainNewsIndexにインスタンスを格納。<br>
mainNewsIndexから、さらに"headline"クラスを抽出。<br>
取得したい&lt;span&gt;タグの"headline"クラスは複数存在するので、find_all()でまとめて抽出。<br>
これで最終的には、"bs4.element.Tag"型のインスタンスのリストがheadlinesに格納される。</p>

<ul>
<li>find()</li>
<li>find_all()</li>
</ul>

<p>以上2つのメソッドは、フィルターをかけて要素を取得する。<br>
フィルターのかけ方については、わかりやすくまとめてくださっています。<br>
<a href="https://qiita.com/itkr/items/513318a9b5b92bd56185" id="reference-86489cf63eb440462101">PythonとBeautiful Soupでスクレイピング</a><br>
<a href="http://mankuro.hateblo.jp/entry/2017/05/02/beautifulsoup4-find-and-find_all/" rel="nofollow noopener" target="_blank">萬九郎の硬い船</a></p>

<h2>
<span id="bs4elementtagとは" class="fragment"></span><a href="#bs4elementtag%E3%81%A8%E3%81%AF"><i class="fa fa-link"></i></a>bs4.element.Tag　とは</h2>

<ul>
<li>find()</li>
<li>find_all()</li>
</ul>

<p>これらを用いると最終的に返されるインスタンス。<br>
中身を見てみる。</p>

<h3>
<span id="コード-1" class="fragment"></span><a href="#%E3%82%B3%E3%83%BC%E3%83%89-1"><i class="fa fa-link"></i></a>コード</h3>

<div class="code-frame" data-lang="py"><div class="highlight"><pre>
<span class="kn">import</span> <span class="nn">pprint</span>

<span class="o">~</span><span class="p">(</span><span class="err">中略</span><span class="p">)</span><span class="o">~</span>

<span class="k">for</span> <span class="n">headline</span> <span class="ow">in</span> <span class="n">headlines</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">headline</span><span class="p">))</span>
    <span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">headline</span><span class="o">.</span><span class="n">__dict__</span><span class="p">)</span>
</pre></div></div>

<h3>
<span id="実行結果" class="fragment"></span><a href="#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C"><i class="fa fa-link"></i></a>実行結果</h3>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>&lt;class 'bs4.element.Tag'&gt;
{'attrs': {'class': ['headline']},
'can_be_empty_element': False,
'contents': ['栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る', &lt;span class="update"&gt;（18:05）&lt;/span&gt;],
'hidden': False,
'known_xml': False,
'name': 'span',
'namespace': None,
'next_element': '栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る',
'next_sibling': '\n',
'parent': &lt;a href="http://www.yomiuri.co.jp/sports/sumo/20180521-OYT1T50054.html?from=ytop_main9"&gt;
         &lt;span class="headline"&gt;栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る&lt;span class="update"&gt;（18:05）&lt;/span&gt;&lt;/span&gt;
         &lt;span class="icon-photo"&gt;&lt;/span&gt;
         &lt;/a&gt;,
'parser_class': &lt;class 'bs4.BeautifulSoup'&gt;,
'prefix': None,
'preserve_whitespace_tags': {'textarea', 'pre'},
'previous_element': '\n',
'previous_sibling': '\n'}
</pre></div></div>

<p>このように様々な情報が辞書型で格納されている。<br>
もちろん、「.key」でつなぐことでこれらのvalueを取得できる。</p>

<div class="code-frame" data-lang="py"><div class="highlight"><pre>
<span class="c1">#タグ直下のテキストを取得する
</span><span class="n">headline</span><span class="o">.</span><span class="n">contents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1">#時刻を取得する
</span><span class="n">headline</span><span class="o">.</span><span class="n">span</span><span class="o">.</span><span class="n">contents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div></div>

<ul>
<li>.string</li>
<li>.text (指定場所以下のテキストを全て取得)</li>
</ul>

<p>としてもテキスト内容は取得できる。<br>
しかし、タグが多重構造の場合、外側のみのテキスト内容取得ができなかったので<br>
.contents[] で指定して取得するのがよさそう。</p>

<h1>
<span id="まとめ" class="fragment"></span><a href="#%E3%81%BE%E3%81%A8%E3%82%81"><i class="fa fa-link"></i></a>まとめ</h1>

<p>スクレイピングの基礎とBeautiful Soup4についてまとめました。<br>
次回は一定時間毎にこれらを動作させるプログラムを書いてみたいと思いますー</p>
</div></div></section><div class="it-Footer"><div class="it-Footer_actions"><div class="it-Footer_editRequest"><a href="/drafts/896c49d46585e32ff7b1/edit" class="u-link-no-underline"><span class="fa fa-fw fa-code-fork"></span><span>編集リクエスト</span></a></div><div class="it-Footer_stock"><button><span class="fa fa-folder-open"></span><span class="it-Footer_stockLabel">ストック</span></button></div><div class="it-Footer_like"><button><span class="fa fa-fw fa-thumbs-up"></span><span>いいね</span></button><a href="/U-MA/items/896c49d46585e32ff7b1/likers" class="it-Footer_likeCount">159</a></div></div><div class="it-Footer_social"><div class="it-Footer_shareButton it-Footer_shareButton-twitter"><span class="fa fa-twitter"></span></div><div class="it-Footer_shareButton it-Footer_shareButton-facebook"><span class="fa fa-facebook"></span></div></div></div><div class="ai-Container" itemProp="author" itemscope="" itemType="http://schema.org/Person"><div class="ai-User"><a href="/U-MA"><img src="https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F252009%2Fprofile-images%2F1526810038?ixlib=rb-1.2.2&amp;auto=compress%2Cformat&amp;lossless=0&amp;w=75&amp;s=c2e01483f204e471193c88e85451b059" alt="U-MA" class="ai-User_image" itemProp="image"/></a><div class="ai-User_body"><div class="ai-User_header"><a href="/U-MA" class="ai-User_name"></a><a href="/U-MA" class="ai-User_urlname" itemProp="name">@<!-- -->U-MA</a></div><div class="ai-User_description">22歳のぺーぺー
職場ではJava研修。
プライベートではPythonで遊んでいる18卒です。

学んだことやプロダクトをアウトプットしていきます。
よろしくお願いします。</div><div class="ai-User_footer"><button class="it-UserFollowButton it-UserFollowButton-follow">フォロー</button></div></div></div></div><div class="apm-Content"><div class="apm-Content_title">ユーザー登録して、Qiitaをもっと便利に使ってみませんか。</div><ol class="apm-Content_list"><li>あなたにマッチした記事をお届けします<div class="description">ユーザーやタグをフォローすることで、あなたが興味を持つ技術分野の情報をまとめてキャッチアップできます</div></li><li>便利な情報をあとで効率的に読み返せます<div class="description">気に入った記事を「ストック」することで、あとからすぐに検索できます</div></li><div><a class="apm-Content_help" href="https://help.qiita.com/ja/articles/qiita-login-user" target="_blank"><i class="fa fa-fw fa-arrow-circle-right"></i>より詳しく</a></div></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2FU-MA%2Fitems%2F896c49d46585e32ff7b1&amp;realm=qiita" class="apm-Content_button apm-Content_button-signup">登録する</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2FU-MA%2Fitems%2F896c49d46585e32ff7b1&amp;realm=qiita" class="apm-Content_button apm-Content_button-signin">ログインする</a></div></div></div><div class="p-items_options"><div class="mt-2"></div></div><div class="p-items_toc"><div class="mt-2"></div></div></div></div><div class="p-items_wrapper p-items_wrapper-white"><div class="p-items_container"><div class="p-items_leftDummy"></div><div class="p-items_main"><div class="p-items_aside px-5 p-2@s"><div id="logly-lift-4279493"><div class="tl-DummyItemList p-2"><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div><div class="tl-DummyItemList_content tl-DummyItem"><div class="tl-DummyItem_image mr-1"></div><div class="tl-DummyItem_body"><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div><div class="tl-DummyItem_text mb-1"></div></div></div></div></div></div><div class="p-items_aside mt-5 px-5 p-2@s"></div><div></div><div class="p-items_aside mt-6 px-5 p-2@s" id="comments-wrapper"><div id="comments" class="co-ItemWrapper"><div class="co-ItemWrapper_title mb-2"><span class="fa fa-comments mr-1"></span>コメント</div><div class="co-AnonymousForm p-3"><div class="co-AnonymousForm_title mb-1">あなたもコメントしてみませんか :)</div><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2FU-MA%2Fitems%2F896c49d46585e32ff7b1&amp;realm=qiita" class="co-AnonymousForm_signup">ユーザ登録</a><div class="co-AnonymousForm_sub mt-1">すでにアカウントを持っている方は<a href="/login?callback_action=login_or_signup&amp;redirect_to=%2FU-MA%2Fitems%2F896c49d46585e32ff7b1&amp;realm=qiita" class="co-AnonymousForm_login">ログイン</a></div></div></div></div></div><div class="p-items_rightDummy"></div></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="PersonalPublicArticle" data-dom-id="PersonalPublicArticle-react-component-e1891f0f-ea8a-42d5-a22d-d44774ac946c">{"article":{"body":"\n\u003ch1\u003e\n\u003cspan id=\"概要\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%A6%82%E8%A6%81\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e概要\u003c/h1\u003e\n\n\u003cp\u003epythonを使って何かやりたいと思っている今日このごろ、、、\u003cbr\u003e\n\u003cdel\u003eエロい\u003c/del\u003e健全な画像を自動収集したいなーと思って今流行りのスクレイピングをやってみました。\u003cbr\u003e\nBeautiful Soupについて調べたので、基礎的なことをまとめておきます。\u003cbr\u003e\n作成者が初学者のため、完全初学者向けです。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"スクレイピングとは\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0%E3%81%A8%E3%81%AF\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eスクレイピングとは?\u003c/h1\u003e\n\n\u003cp\u003eまずはスクレイピングとは何かの確認。\u003cbr\u003e\nwikipedia先生より。\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eウェブスクレイピング（英: Web scraping）とは、ウェブサイトから情報を抽出するコンピュータソフトウェア技術のこと。\u003cbr\u003e\n~中略~\u003cbr\u003e\nウェブスクレイピングではウェブ上の非構造化データの変換、一般的にはHTMLフォーマットからデータベースやスプレッドシートに格納・分析可能な構造化データへの変換に、より焦点が当てられている。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e構造化データ/非構造化データとは、簡単にまとめると\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e構造化データ\n\n\u003cul\u003e\n\u003cli\u003eCSVファイル, Excelファイル 等\u003c/li\u003e\n\u003cli\u003e「行」, 「列」 によって、データが明確に分類できる。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e非構造化データ\n\n\u003cul\u003e\n\u003cli\u003ehtmlファイル, Jsonファイル, テキストデータ 等\u003c/li\u003e\n\u003cli\u003e「行」, 「列」 だけでは分類ができない。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e「行」, 「列」でデータを管理したほうが、コンピュータ的に都合がいい。\u003cbr\u003e\nつまるところ、スクレイピングとは\u003cbr\u003e\n\u003cb\u003e「非構造化データから情報を抽出して、コンピュータがより扱い易い構造化データに格納する」\u003c/b\u003e\u003cbr\u003e\nことが目的ともいえる。\u003c/p\u003e\n\n\u003cp\u003eちなみに、webサイトからデータを取得する「クローリング」というものもある。\u003cbr\u003e\nクローリングは情報の抽出ではなく、任意のデータを取得することを指す。\u003cbr\u003e\n「スクレイピング」は、htmlファイル全体を取得しその中から目的のデータを抽出すること。\u003cbr\u003e\n「クローリング」は、htmlファイル全体, あるいは目的のデータをそのまま取得すること。\u003cbr\u003e\n\u003cb\u003e「\u003cem\u003eクローリング\u003c/em\u003e」したhtmlファイルを「\u003cem\u003eスクレイピング\u003c/em\u003e」する\u003c/b\u003e\u003cbr\u003e\nと考えるとわかりやすい。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"beautiful-soupとは\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#beautiful-soup%E3%81%A8%E3%81%AF\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eBeautiful Soupとは?\u003c/h1\u003e\n\n\u003cp\u003e\u003cb\u003ePythonのライブラリの一つで、スクレイピングに特化したモジュール\u003c/b\u003e。\u003cbr\u003e\nhtmlファイルをタグ情報から解析し、抽出データを格納したインスタンスを返す。\u003cbr\u003e\nhtmlの構造とpythonの基礎が分かっていれば、非常に使いやすい。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"やってみよう\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eやってみよう\u003c/h1\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"環境\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%92%B0%E5%A2%83\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e環境\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eMac OS High Sierra ver 10.13.4\u003c/li\u003e\n\u003cli\u003ePython 3.6.5 (anaconda)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"環境構築\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e環境構築\u003c/h2\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"仮想環境の作成\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E4%BB%AE%E6%83%B3%E7%92%B0%E5%A2%83%E3%81%AE%E4%BD%9C%E6%88%90\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e仮想環境の作成\u003c/h3\u003e\n\n\u003cp\u003eスクレイピング用の仮想環境を作成する。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"text\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003emkdir [dir_name]\ncd [dir_name]\npython -m venv [env_name]\nsource [env_name]/bin/activate\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e仮想環境を構築完了。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"仮想環境にbeautiful-soupをインストール\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E4%BB%AE%E6%83%B3%E7%92%B0%E5%A2%83%E3%81%ABbeautiful-soup%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e仮想環境にBeautiful Soupをインストール\u003c/h3\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"py\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\n\u003cspan class=\"n\"\u003epip\u003c/span\u003e \u003cspan class=\"n\"\u003einstall\u003c/span\u003e \u003cspan class=\"n\"\u003ebeautifulsoup4\u003c/span\u003e\n\u003cspan class=\"n\"\u003epip\u003c/span\u003e \u003cspan class=\"nb\"\u003elist\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003ebeautifulsoup4 が表示されていたら成功。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"beautiful-soupを動かしてみる\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#beautiful-soup%E3%82%92%E5%8B%95%E3%81%8B%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eBeautiful Soupを動かしてみる\u003c/h2\u003e\n\n\u003cp\u003ehtmlファイルの取得には、pythonの標準搭載モジュールである\u003cb\u003eurllib\u003c/b\u003eを使用。\u003cbr\u003e\n読売新聞のヘッドラインを取得するコードを書いた。\u003cbr\u003e\n\u003ca href=\"http://www.yomiuri.co.jp/\" rel=\"nofollow noopener\" target=\"_blank\"\u003e読売新聞\u003c/a\u003eのページソースを確認しながらだと、以下の記事が理解しやすい。\u003cbr\u003e\n\"list-main-news\"クラス内の\"headline\"クラスのテキストを取得する。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"コード\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%B3%E3%83%BC%E3%83%89\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eコード\u003c/h3\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"py\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\n\u003cspan class=\"c1\"\u003e#coding: UTF-8\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eurllib\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ebs4\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003escraping\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e#url\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"http://www.yomiuri.co.jp/\"\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e#get html\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eurlopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e#set BueatifulSoup\n\u003c/span\u003e    \u003cspan class=\"n\"\u003esoup\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"html.parser\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e#get headlines\n\u003c/span\u003e    \u003cspan class=\"n\"\u003emainNewsIndex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esoup\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efind\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"ul\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eattrs\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"list-main-news\"\u003c/span\u003e\u003cspan class=\"p\"\u003e})\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eheadlines\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emainNewsIndex\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efind_all\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"span\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eattrs\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"headline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e})\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e#print headlines\n\u003c/span\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eheadline\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eheadlines\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eheadline\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtents\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eheadline\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003espan\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003e__name__\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s\"\u003e\"__main__\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"n\"\u003escraping\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"実行結果2018521\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C2018521\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実行結果(2018/5/21)\u003c/h3\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"text\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e省庁データ、近く西暦で統一…来春は間に合わず （07:16）\n内閣支持、３ポイント増の４２％…読売世論調査 （06:00）\n政党支持、自民３７％・立民７％…読売世論調査 （22:33）\n働き方法案「今国会で」２５％…読売世論調査 （23:10）\n米朝会談で核解決「期待」６６％…読売世論調査 （06:00）\nヒデキにこの勝利捧げる…交流のＪ１川崎が追悼 （07:29）\n日大監督「かんさい学院」連呼、謝る大学名誤る （12:46）\n駅を１９００ｍ通過、時速６０キロで後進し戻る （19:22）\nスマホで徘徊者捜索実験、ＧＰＳ内蔵靴「有用」 （07:38）\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"解説\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E8%A7%A3%E8%AA%AC\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e解説\u003c/h1\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"html-parser\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#html-parser\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003ehtml parser\u003c/h2\u003e\n\n\u003cp\u003ehtml parserとは、htmlのタグ情報から情報を解釈するプログラムのこと。\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eパースとは、プログラムのソースコードやXML文書など、一定の文法に従って記述された複雑な構造のテキスト文書を解析し、プログラムで扱えるようなデータ構造の集合体に変換することである。\u003cbr\u003e\nパースを行うためのプログラムの総称を「パーサ/パーザ」という。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e(\u003ca href=\"http://www.protosolution.co.jp/glossary/web/ha/pa-su.html\" rel=\"nofollow noopener\" target=\"_blank\"\u003eProto Solution\u003c/a\u003eより)\u003c/p\u003e\n\n\u003cp\u003ehtml parserは、html.parser以外にも多数存在する。\u003cbr\u003e\n本記事では標準搭載の「html.parser」を使用。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"py\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\n\u003cspan class=\"n\"\u003esoup\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBeautifulSoup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"html.parser\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eBeautifulSoupにhtmlファイルとhtml parserを渡し、インスタンス作成。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"beautiful-soupの操作\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#beautiful-soup%E3%81%AE%E6%93%8D%E4%BD%9C\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eBeautiful Soupの操作\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003efind()\n\n\u003cul\u003e\n\u003cli\u003e一番最初に合致した結果のみを返す\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003efind_all()\n\n\u003cul\u003e\n\u003cli\u003e合致した結果を全てリストで返す\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eこの2つのメソッドが主に使用される。\u003cbr\u003e\n引数でフィルタをかけることにより、任意のhtmlタグ内の情報を保持した\u003cbr\u003e\n\u003cb\u003ebs4.element.Tag\u003c/b\u003e型のインスタンスを取得できる。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"py\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\n\u003cspan class=\"n\"\u003emainNewsIndex\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esoup\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efind\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"ul\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eattrs\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"list-main-news\"\u003c/span\u003e\u003cspan class=\"p\"\u003e})\u003c/span\u003e\n\u003cspan class=\"n\"\u003eheadlines\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emainNewsIndex\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efind_all\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"span\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eattrs\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"headline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e})\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eまず、\u003ca href=\"http://www.yomiuri.co.jp/\" rel=\"nofollow noopener\" target=\"_blank\"\u003e読売新聞\u003c/a\u003eのページには\"list-main-news\"クラスが一つしか存在しない。\u003cbr\u003e\nそのため、find()を使用する。(find_all()だと、htmlファイル全体を探索してしまう。)\u003cbr\u003e\nhtmlファイル全体から\u0026lt;ul\u0026gt;タグの \"list-main-news\" クラスを抽出し、\u003cbr\u003e\nmainNewsIndexにインスタンスを格納。\u003cbr\u003e\nmainNewsIndexから、さらに\"headline\"クラスを抽出。\u003cbr\u003e\n取得したい\u0026lt;span\u0026gt;タグの\"headline\"クラスは複数存在するので、find_all()でまとめて抽出。\u003cbr\u003e\nこれで最終的には、\"bs4.element.Tag\"型のインスタンスのリストがheadlinesに格納される。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003efind()\u003c/li\u003e\n\u003cli\u003efind_all()\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e以上2つのメソッドは、フィルターをかけて要素を取得する。\u003cbr\u003e\nフィルターのかけ方については、わかりやすくまとめてくださっています。\u003cbr\u003e\n\u003ca href=\"https://qiita.com/itkr/items/513318a9b5b92bd56185\" id=\"reference-86489cf63eb440462101\"\u003ePythonとBeautiful Soupでスクレイピング\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"http://mankuro.hateblo.jp/entry/2017/05/02/beautifulsoup4-find-and-find_all/\" rel=\"nofollow noopener\" target=\"_blank\"\u003e萬九郎の硬い船\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"bs4elementtagとは\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#bs4elementtag%E3%81%A8%E3%81%AF\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003ebs4.element.Tag　とは\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003efind()\u003c/li\u003e\n\u003cli\u003efind_all()\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eこれらを用いると最終的に返されるインスタンス。\u003cbr\u003e\n中身を見てみる。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"コード-1\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%B3%E3%83%BC%E3%83%89-1\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eコード\u003c/h3\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"py\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epprint\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e~\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"err\"\u003e中略\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e~\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eheadline\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eheadlines\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003etype\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eheadline\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epprint\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eheadline\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003e__dict__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"実行結果\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実行結果\u003c/h3\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"text\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\u0026lt;class 'bs4.element.Tag'\u0026gt;\n{'attrs': {'class': ['headline']},\n'can_be_empty_element': False,\n'contents': ['栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る', \u0026lt;span class=\"update\"\u0026gt;（18:05）\u0026lt;/span\u0026gt;],\n'hidden': False,\n'known_xml': False,\n'name': 'span',\n'namespace': None,\n'next_element': '栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る',\n'next_sibling': '\\n',\n'parent': \u0026lt;a href=\"http://www.yomiuri.co.jp/sports/sumo/20180521-OYT1T50054.html?from=ytop_main9\"\u0026gt;\n         \u0026lt;span class=\"headline\"\u0026gt;栃ノ心、無傷の９連勝…白鵬と鶴竜は１敗守る\u0026lt;span class=\"update\"\u0026gt;（18:05）\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\n         \u0026lt;span class=\"icon-photo\"\u0026gt;\u0026lt;/span\u0026gt;\n         \u0026lt;/a\u0026gt;,\n'parser_class': \u0026lt;class 'bs4.BeautifulSoup'\u0026gt;,\n'prefix': None,\n'preserve_whitespace_tags': {'textarea', 'pre'},\n'previous_element': '\\n',\n'previous_sibling': '\\n'}\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eこのように様々な情報が辞書型で格納されている。\u003cbr\u003e\nもちろん、「.key」でつなぐことでこれらのvalueを取得できる。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"py\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre\u003e\n\u003cspan class=\"c1\"\u003e#タグ直下のテキストを取得する\n\u003c/span\u003e\u003cspan class=\"n\"\u003eheadline\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtents\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e#時刻を取得する\n\u003c/span\u003e\u003cspan class=\"n\"\u003eheadline\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003espan\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtents\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cul\u003e\n\u003cli\u003e.string\u003c/li\u003e\n\u003cli\u003e.text (指定場所以下のテキストを全て取得)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eとしてもテキスト内容は取得できる。\u003cbr\u003e\nしかし、タグが多重構造の場合、外側のみのテキスト内容取得ができなかったので\u003cbr\u003e\n.contents[] で指定して取得するのがよさそう。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"まとめ\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%BE%E3%81%A8%E3%82%81\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eまとめ\u003c/h1\u003e\n\n\u003cp\u003eスクレイピングの基礎とBeautiful Soup4についてまとめました。\u003cbr\u003e\n次回は一定時間毎にこれらを動作させるプログラムを書いてみたいと思いますー\u003c/p\u003e\n","createdAt":"2018-05-21T11:59:01Z","elapsedYearsFromUpdatedAt":1,"isDeprecated":true,"isDestroyableByViewer":false,"isEditRequestSendableByViewer":true,"isLikableByViewer":true,"isLikedByViewer":false,"isPublic":true,"isSlide":false,"isStockableByViewer":true,"isStockedByViewer":false,"isUpdatableByViewer":false,"isUpdated":true,"likesCount":159,"originalId":648045,"title":"Beautiful Soup での スクレイピング基礎まとめ [初学者向け]","toc":"\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%A6%82%E8%A6%81\"\u003e概要\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0%E3%81%A8%E3%81%AF\"\u003eスクレイピングとは?\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#beautiful-soup%E3%81%A8%E3%81%AF\"\u003eBeautiful Soupとは?\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86\"\u003eやってみよう\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%92%B0%E5%A2%83\"\u003e環境\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89\"\u003e環境構築\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E4%BB%AE%E6%83%B3%E7%92%B0%E5%A2%83%E3%81%AE%E4%BD%9C%E6%88%90\"\u003e仮想環境の作成\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E4%BB%AE%E6%83%B3%E7%92%B0%E5%A2%83%E3%81%ABbeautiful-soup%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\"\u003e仮想環境にBeautiful Soupをインストール\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#beautiful-soup%E3%82%92%E5%8B%95%E3%81%8B%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B\"\u003eBeautiful Soupを動かしてみる\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%B3%E3%83%BC%E3%83%89\"\u003eコード\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C2018521\"\u003e実行結果(2018/5/21)\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E8%A7%A3%E8%AA%AC\"\u003e解説\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#html-parser\"\u003ehtml parser\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#beautiful-soup%E3%81%AE%E6%93%8D%E4%BD%9C\"\u003eBeautiful Soupの操作\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#bs4elementtag%E3%81%A8%E3%81%AF\"\u003ebs4.element.Tag　とは\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%B3%E3%83%BC%E3%83%89-1\"\u003eコード\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C\"\u003e実行結果\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%BE%E3%81%A8%E3%82%81\"\u003eまとめ\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","totalPv":45566,"updatedAt":"2018-05-22T22:54:00Z","uuid":"896c49d46585e32ff7b1","adventCalendarItem":null,"author":{"description":"22歳のぺーぺー\r\n職場ではJava研修。\r\nプライベートではPythonで遊んでいる18卒です。\r\n\r\n学んだことやプロダクトをアウトプットしていきます。\r\nよろしくお願いします。","name":"","profileImageUrl":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F252009%2Fprofile-images%2F1526810038?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=787411360b8d778d1ba58c3830830070","profileImageUrlW48":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F252009%2Fprofile-images%2F1526810038?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=787411360b8d778d1ba58c3830830070","profileImageUrlW75":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F252009%2Fprofile-images%2F1526810038?ixlib=rb-1.2.2\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=c2e01483f204e471193c88e85451b059","urlName":"U-MA","isFollowedByViewer":false,"isFollowableByViewer":true,"websiteUrl":"","organizations":{"edges":[]}},"tags":[{"name":"スクレイピング","urlName":"%e3%82%b9%e3%82%af%e3%83%ac%e3%82%a4%e3%83%94%e3%83%b3%e3%82%b0"},{"name":"初心者","urlName":"%e5%88%9d%e5%bf%83%e8%80%85"},{"name":"Python3","urlName":"python3"},{"name":"備忘録","urlName":"%e5%82%99%e5%bf%98%e9%8c%b2"},{"name":"BeautifulSoup","urlName":"beautifulsoup"}],"followingLikers":{"edges":[]},"comments":{"totalCount":0}},"viewer":null,"analyticsTrackingId":null}</script>
      
<footer id="globalFooter" class="st-Footer"><div class="st-Footer_container"><div class="st-Footer_start"><div class="st-Footer_logo"><svg viewbox="0 0 426.57 130" xmlns="http://www.w3.org/2000/svg"><circle cx="167.08" cy="21.4" r="12.28" /><path d="M250.81 29.66h23.48v18.9h-23.48z" /><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z" /><circle cx="216.33" cy="21.4" r="12.28" /></svg></div><div class="st-Footer_catchcopy">How developers code is here.</div><div class="st-Footer_socials"><a class="fa fa-twitter" href="https://twitter.com/qiita"></a><a class="fa fa-facebook-square" href="https://www.facebook.com/qiita/"></a></div></div><div class="st-Footer_end"><div class="st-Footer_qiita"><div class="st-Footer_label">Qiita</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="/about">About</a><a href="/terms">利用規約</a><a href="/privacy">プライバシー</a><a target="_blank" href="http://help.qiita.com/ja/articles/qiita-community-guideline">ガイドライン</a></div><div class="st-Footer_column"><a href="/api/v2/docs">API</a><a href="/feedback/new">ご意見</a><a href="https://help.qiita.com">ヘルプ</a><a target="_blank" href="https://qiita.com/ads?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">広告掲載</a></div></div></div><div class="st-Footer_increments"><div class="st-Footer_label">Increments</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="https://increments.co.jp/company/">About</a><a href="https://increments.co.jp/jobs/">採用情報</a><a href="https://blog.qiita.com">ブログ</a></div><div class="st-Footer_column"><a href="https://teams.qiita.com/">Qiita Team</a><a href="https://jobs.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Jobs</a><a href="https://zine.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Zine</a></div></div></div></div></div><div class="st-Footer_copyright">© 2011-2019 Increments Inc.</div></footer><div class="p-messages"><div id="Snackbar-react-component-2fa705f2-73f9-43c3-b74c-2f848cd06c44"><div class="msg-Container"><div class="msg-Item msg-Item- msg-Item-dismissible" style="visibility:hidden;opacity:0;transition:visibility 0ms 50ms, opacity 50ms linear"><div class="msg-Item_body"></div><button class="msg-Item_dismiss"><span class="fa fa-close"></span></button></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="Snackbar" data-dom-id="Snackbar-react-component-2fa705f2-73f9-43c3-b74c-2f848cd06c44">{}</script>
      
</div><div id="LoginModal-react-component-c7f41126-92cf-4b7d-84c8-f663b567b286"><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body lm-Dialog"><div class="fa fa-times lm-Dialog_close"></div><div class="lm-Dialog_title">ユーザー登録して、Qiitaをもっと便利に使ってみませんか。</div><div class="lm-Dialog_message-pc">この機能を利用するにはログインする必要があります。ログインするとさらに便利にQiitaを利用できます。</div><div class="lm-Dialog_message-mobile">この機能を利用するにはログインする必要があります。ログインするとさらに便利にQiitaを利用できます。</div><ol class="lm-Dialog_list"><li>あなたにマッチした記事をお届けします<div class="description">ユーザーやタグをフォローすることで、あなたが興味を持つ技術分野の情報をまとめてキャッチアップできます</div></li><li>便利な情報をあとで効率的に読み返せます<div class="description">気に入った記事を「ストック」することで、あとからすぐに検索できます</div></li></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2FU-MA%2Fitems%2F896c49d46585e32ff7b1&amp;realm=qiita" class="lm-Dialog_button lm-Dialog_button-signup">登録する</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2FU-MA%2Fitems%2F896c49d46585e32ff7b1&amp;realm=qiita" class="lm-Dialog_button lm-Dialog_button-signin">ログインする</a></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="LoginModal" data-dom-id="LoginModal-react-component-c7f41126-92cf-4b7d-84c8-f663b567b286">{}</script>
      
</div><div id="dataContainer" style="display: none;" data-config="{&quot;actionPath&quot;:&quot;public/items#show&quot;,&quot;settings&quot;:{&quot;analyticsTrackingId&quot;:&quot;UA-24675221-12&quot;,&quot;mixpanelToken&quot;:&quot;17d24b448ca579c365d2d1057f3a1791&quot;,&quot;assetsMap&quot;:{},&quot;csrfToken&quot;:&quot;KMNoQyV1fIhNfABkBqltlH/vZ9XDISdSTtgc+80ojYEJalebIeYCtdVpsPTrfiZ7r6w+rMvvxX8sAkdE7Naxqg==&quot;,&quot;locale&quot;:&quot;ja&quot;},&quot;currentUser&quot;:null}" /></body></html><script type="application/json" data-js-react-on-rails-store="AppStore">{"snackbar":{"type":"","body":"","isActive":false}}</script>